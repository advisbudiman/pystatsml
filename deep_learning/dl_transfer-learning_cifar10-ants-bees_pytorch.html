
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Transfer Learning Tutorial &#8212; Statistics and Machine Learning in Python 0.5 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <link rel="search" type="application/opensearchdescription+xml"
          title="Search within Statistics and Machine Learning in Python 0.5 documentation"
          href="../_static/opensearch.xml"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Convolutional neural network" href="dl_cnn_cifar10_pytorch.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="transfer-learning-tutorial">
<h1>Transfer Learning Tutorial<a class="headerlink" href="#transfer-learning-tutorial" title="Permalink to this headline">¶</a></h1>
<p>Sources:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://cs231n.github.io/transfer-learning/">cs231n &#64; Stanford</a></p></li>
<li><p><a class="reference external" href="https://chsasank.github.io">Sasank Chilamkurthy</a></p></li>
</ul>
<p>Quote <a class="reference external" href="https://cs231n.github.io/transfer-learning/">cs231n &#64;
Stanford</a>:</p>
<p>In practice, very few people train an entire Convolutional Network from
scratch (with random initialization), because it is relatively rare to
have a dataset of sufficient size. Instead, it is common to pretrain a
ConvNet on a very large dataset (e.g. ImageNet, which contains 1.2
million images with 1000 categories), and then use the ConvNet either as
an initialization or a fixed feature extractor for the task of interest.</p>
<p>These two major transfer learning scenarios look as follows:</p>
<ul>
<li><p><strong>ConvNet as fixed feature extractor</strong>:</p>
<ul class="simple">
<li><p>Take a ConvNet pretrained on ImageNet,</p></li>
<li><p>Remove the last fully-connected layer (this layer’s outputs are
the 1000 class scores for a different task like ImageNet)</p></li>
<li><p>Treat the rest of the ConvNet as a fixed feature extractor for the
new dataset.</p></li>
</ul>
<p>In practice:</p>
<ul class="simple">
<li><p>Freeze the weights for all of the network except that of the final
fully connected layer. This last fully connected layer is replaced
with a new one with random weights and only this layer is trained.</p></li>
</ul>
</li>
<li><p><strong>Finetuning the convnet</strong>:</p></li>
</ul>
<p>fine-tune the weights of the pretrained network by continuing the
backpropagation. It is possible to fine-tune all the layers of the
ConvNet</p>
<p>Instead of random initializaion, we initialize the network with a
pretrained network, like the one that is trained on imagenet 1000
dataset. Rest of the training looks as usual.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">lr_scheduler</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">models</span>
<span class="c1">#</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Device configuration</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cpu&#39;</span> <span class="c1"># Force CPU</span>
</pre></div>
</div>
<section id="training-function">
<h2>Training function<a class="headerlink" href="#training-function" title="Permalink to this headline">¶</a></h2>
<p>Combine train and test/validation into a single function.</p>
<p>Now, let’s write a general function to train a model. Here, we will
illustrate:</p>
<ul class="simple">
<li><p>Scheduling the learning rate</p></li>
<li><p>Saving the best model</p></li>
</ul>
<p>In the following, parameter <code class="docutils literal notranslate"><span class="pre">scheduler</span></code> is an LR scheduler object from
<code class="docutils literal notranslate"><span class="pre">torch.optim.lr_scheduler</span></code>.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># %load train_val_model.py</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">copy</span>


<span class="k">def</span> <span class="nf">train_val_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloaders</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span>
        <span class="n">scheduler</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">log_interval</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

    <span class="n">since</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="n">best_model_wts</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
    <span class="n">best_acc</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="c1"># Store losses and accuracies accross epochs</span>
    <span class="n">losses</span><span class="p">,</span> <span class="n">accuracies</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">train</span><span class="o">=</span><span class="p">[],</span> <span class="n">val</span><span class="o">=</span><span class="p">[]),</span> <span class="nb">dict</span><span class="p">(</span><span class="n">train</span><span class="o">=</span><span class="p">[],</span> <span class="n">val</span><span class="o">=</span><span class="p">[])</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">log_interval</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">log_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">num_epochs</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>

        <span class="c1"># Each epoch has a training and validation phase</span>
        <span class="k">for</span> <span class="n">phase</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;val&#39;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s1">&#39;train&#39;</span><span class="p">:</span>
                <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>  <span class="c1"># Set model to training mode</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>   <span class="c1"># Set model to evaluate mode</span>

            <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="n">running_corrects</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="c1"># Iterate over data.</span>
            <span class="n">nsamples</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">dataloaders</span><span class="p">[</span><span class="n">phase</span><span class="p">]:</span>
                <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">nsamples</span> <span class="o">+=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

                <span class="c1"># zero the parameter gradients</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

                <span class="c1"># forward</span>
                <span class="c1"># track history if only in train</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">set_grad_enabled</span><span class="p">(</span><span class="n">phase</span> <span class="o">==</span> <span class="s1">&#39;train&#39;</span><span class="p">):</span>
                    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
                    <span class="n">_</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

                    <span class="c1"># backward + optimize only if in training phase</span>
                    <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s1">&#39;train&#39;</span><span class="p">:</span>
                        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

                <span class="c1"># statistics</span>
                <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">inputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">running_corrects</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">preds</span> <span class="o">==</span> <span class="n">labels</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">scheduler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">phase</span> <span class="o">==</span> <span class="s1">&#39;train&#39;</span><span class="p">:</span>
                <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="c1">#nsamples = dataloaders[phase].dataset.data.shape[0]</span>
            <span class="n">epoch_loss</span> <span class="o">=</span> <span class="n">running_loss</span> <span class="o">/</span> <span class="n">nsamples</span>
            <span class="n">epoch_acc</span> <span class="o">=</span> <span class="n">running_corrects</span><span class="o">.</span><span class="n">double</span><span class="p">()</span> <span class="o">/</span> <span class="n">nsamples</span>

            <span class="n">losses</span><span class="p">[</span><span class="n">phase</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch_loss</span><span class="p">)</span>
            <span class="n">accuracies</span><span class="p">[</span><span class="n">phase</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch_acc</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">log_interval</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">log_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1"> Loss: </span><span class="si">{:.4f}</span><span class="s1"> Acc: </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">phase</span><span class="p">,</span> <span class="n">epoch_loss</span><span class="p">,</span> <span class="n">epoch_acc</span><span class="p">))</span>

            <span class="c1"># deep copy the model</span>
            <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s1">&#39;val&#39;</span> <span class="ow">and</span> <span class="n">epoch_acc</span> <span class="o">&gt;</span> <span class="n">best_acc</span><span class="p">:</span>
                <span class="n">best_acc</span> <span class="o">=</span> <span class="n">epoch_acc</span>
                <span class="n">best_model_wts</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">log_interval</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">log_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">()</span>

    <span class="n">time_elapsed</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">since</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training complete in </span><span class="si">{:.0f}</span><span class="s1">m </span><span class="si">{:.0f}</span><span class="s1">s&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">time_elapsed</span> <span class="o">//</span> <span class="mi">60</span><span class="p">,</span> <span class="n">time_elapsed</span> <span class="o">%</span> <span class="mi">60</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Best val Acc: </span><span class="si">{:4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_acc</span><span class="p">))</span>

    <span class="c1"># load best model weights</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">best_model_wts</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">accuracies</span>
</pre></div>
</div>
</section>
<section id="cifar-10-dataset">
<h2>CIFAR-10 dataset<a class="headerlink" href="#cifar-10-dataset" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="https://github.com/yunjey/pytorch-tutorial">Source Yunjey Choi</a></p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">WD</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">Path</span><span class="o">.</span><span class="n">home</span><span class="p">(),</span> <span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="s2">&quot;pystatml&quot;</span><span class="p">,</span> <span class="s2">&quot;dl_cifar10_pytorch&quot;</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">WD</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="n">WD</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Working dir is:&quot;</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">())</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="s2">&quot;models&quot;</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Image preprocessing modules</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Pad</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">RandomCrop</span><span class="p">(</span><span class="mi">32</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()])</span>

<span class="c1"># CIFAR-10 dataset</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;data/&#39;</span><span class="p">,</span>
                                             <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                             <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span>
                                             <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;data/&#39;</span><span class="p">,</span>
                                            <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                            <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">())</span>

<span class="c1"># Data loader</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>
                                           <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                                           <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">val_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span>
                                          <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                                          <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Put together train and val</span>
<span class="n">dataloaders</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">train</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">val</span><span class="o">=</span><span class="n">val_loader</span><span class="p">)</span>

<span class="c1"># Info about the dataset</span>
<span class="n">data_shape</span> <span class="o">=</span> <span class="n">dataloaders</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
<span class="n">D_in</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">data_shape</span><span class="p">)</span>
<span class="n">D_out</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">dataloaders</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">targets</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Datasets shape&quot;</span><span class="p">,</span> <span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">dataloaders</span><span class="p">[</span><span class="n">x</span><span class="p">]</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;val&#39;</span><span class="p">]})</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;N input features&quot;</span><span class="p">,</span> <span class="n">D_in</span><span class="p">,</span> <span class="s2">&quot;N output&quot;</span><span class="p">,</span> <span class="n">D_out</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Working</span> <span class="nb">dir</span> <span class="ow">is</span><span class="p">:</span> <span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">ed203246</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">pystatml</span><span class="o">/</span><span class="n">dl_cifar10_pytorch</span>
<span class="n">Files</span> <span class="n">already</span> <span class="n">downloaded</span> <span class="ow">and</span> <span class="n">verified</span>
<span class="n">Datasets</span> <span class="n">shape</span> <span class="p">{</span><span class="s1">&#39;train&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">50000</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="s1">&#39;val&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">)}</span>
<span class="n">N</span> <span class="nb">input</span> <span class="n">features</span> <span class="mi">3072</span> <span class="n">N</span> <span class="n">output</span> <span class="mi">10</span>
</pre></div>
</div>
<section id="finetuning-the-convnet">
<h3>Finetuning the convnet<a class="headerlink" href="#finetuning-the-convnet" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Load a pretrained model and reset final fully connected layer.</p></li>
<li><p>SGD optimizer.</p></li>
</ul>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_ft</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">num_ftrs</span> <span class="o">=</span> <span class="n">model_ft</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">in_features</span>
<span class="c1"># Here the size of each output sample is set to 10.</span>
<span class="n">model_ft</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_ftrs</span><span class="p">,</span> <span class="n">D_out</span><span class="p">)</span>

<span class="n">model_ft</span> <span class="o">=</span> <span class="n">model_ft</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="c1"># Observe that all parameters are being optimized</span>
<span class="n">optimizer_ft</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model_ft</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

<span class="c1"># Decay LR by a factor of 0.1 every 7 epochs</span>
<span class="n">exp_lr_scheduler</span> <span class="o">=</span> <span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer_ft</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="n">model</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">accuracies</span> <span class="o">=</span> <span class="n">train_val_model</span><span class="p">(</span><span class="n">model_ft</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer_ft</span><span class="p">,</span>
    <span class="n">dataloaders</span><span class="p">,</span> <span class="n">scheduler</span><span class="o">=</span><span class="n">exp_lr_scheduler</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">log_interval</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">epochs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">losses</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">losses</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span> <span class="s1">&#39;-b&#39;</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">losses</span><span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">],</span> <span class="s1">&#39;--r&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Epoch</span> <span class="mi">0</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.2476</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.5593</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.9043</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.6818</span>

<span class="n">Epoch</span> <span class="mi">5</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.5791</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.7978</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.5725</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8035</span>

<span class="n">Epoch</span> <span class="mi">10</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.4731</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8351</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.5254</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8217</span>

<span class="n">Epoch</span> <span class="mi">15</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.4581</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8388</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.5220</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8226</span>

<span class="n">Epoch</span> <span class="mi">20</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.4575</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8394</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.5218</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8236</span>

<span class="n">Training</span> <span class="n">complete</span> <span class="ow">in</span> <span class="mi">138</span><span class="n">m</span> <span class="mi">32</span><span class="n">s</span>
<span class="n">Best</span> <span class="n">val</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.825100</span>
</pre></div>
</div>
<img alt="../_images/dl_transfer-learning_cifar10-ants-bees_pytorch_7_1.png" src="../_images/dl_transfer-learning_cifar10-ants-bees_pytorch_7_1.png" />
<p>Adam optimizer</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_ft</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">num_ftrs</span> <span class="o">=</span> <span class="n">model_ft</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">in_features</span>
<span class="c1"># Here the size of each output sample is set to 10.</span>
<span class="n">model_ft</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_ftrs</span><span class="p">,</span> <span class="n">D_out</span><span class="p">)</span>

<span class="n">model_ft</span> <span class="o">=</span> <span class="n">model_ft</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="c1"># Observe that all parameters are being optimized</span>
<span class="n">optimizer_ft</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model_ft</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>

<span class="c1"># Decay LR by a factor of 0.1 every 7 epochs</span>
<span class="n">exp_lr_scheduler</span> <span class="o">=</span> <span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer_ft</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="n">model</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">accuracies</span> <span class="o">=</span> <span class="n">train_val_model</span><span class="p">(</span><span class="n">model_ft</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer_ft</span><span class="p">,</span>
    <span class="n">dataloaders</span><span class="p">,</span> <span class="n">scheduler</span><span class="o">=</span><span class="n">exp_lr_scheduler</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">log_interval</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">epochs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">losses</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">losses</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span> <span class="s1">&#39;-b&#39;</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">losses</span><span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">],</span> <span class="s1">&#39;--r&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Epoch</span> <span class="mi">0</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.0622</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.6341</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.8539</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.7066</span>

<span class="n">Epoch</span> <span class="mi">5</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.5674</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8073</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.5792</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8019</span>

<span class="n">Epoch</span> <span class="mi">10</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.3416</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8803</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.4313</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8577</span>

<span class="n">Epoch</span> <span class="mi">15</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2898</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8980</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.4491</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8608</span>

<span class="n">Epoch</span> <span class="mi">20</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2792</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9014</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.4352</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8631</span>

<span class="n">Training</span> <span class="n">complete</span> <span class="ow">in</span> <span class="mi">147</span><span class="n">m</span> <span class="mi">23</span><span class="n">s</span>
<span class="n">Best</span> <span class="n">val</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.863800</span>
</pre></div>
</div>
<img alt="../_images/dl_transfer-learning_cifar10-ants-bees_pytorch_9_1.png" src="../_images/dl_transfer-learning_cifar10-ants-bees_pytorch_9_1.png" />
</section>
<section id="resnet-as-a-feature-extractor">
<h3>ResNet as a feature extractor<a class="headerlink" href="#resnet-as-a-feature-extractor" title="Permalink to this headline">¶</a></h3>
<p>Freeze all the network except the final layer:
<code class="docutils literal notranslate"><span class="pre">requires_grad</span> <span class="pre">==</span> <span class="pre">False</span></code> to freeze the parameters so that the
gradients are not computed in <code class="docutils literal notranslate"><span class="pre">backward()</span></code>.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_conv</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model_conv</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

<span class="c1"># Parameters of newly constructed modules have requires_grad=True by default</span>
<span class="n">num_ftrs</span> <span class="o">=</span> <span class="n">model_conv</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">in_features</span>
<span class="n">model_conv</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_ftrs</span><span class="p">,</span> <span class="n">D_out</span><span class="p">)</span>

<span class="n">model_conv</span> <span class="o">=</span> <span class="n">model_conv</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="c1"># Observe that only parameters of final layer are being optimized as</span>
<span class="c1"># opposed to before.</span>
<span class="n">optimizer_conv</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model_conv</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

<span class="c1"># Decay LR by a factor of 0.1 every 7 epochs</span>
<span class="n">exp_lr_scheduler</span> <span class="o">=</span> <span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer_conv</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">model</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">accuracies</span> <span class="o">=</span> <span class="n">train_val_model</span><span class="p">(</span><span class="n">model_conv</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer_conv</span><span class="p">,</span>
    <span class="n">dataloaders</span><span class="p">,</span> <span class="n">scheduler</span><span class="o">=</span><span class="n">exp_lr_scheduler</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">log_interval</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">epochs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">losses</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">losses</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span> <span class="s1">&#39;-b&#39;</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">losses</span><span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">],</span> <span class="s1">&#39;--r&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Epoch</span> <span class="mi">0</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.9108</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.3277</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.7846</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.3804</span>

<span class="n">Epoch</span> <span class="mi">5</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.6686</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.4170</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.6981</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.4146</span>

<span class="n">Epoch</span> <span class="mi">10</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.6462</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.4267</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.6768</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.4210</span>

<span class="n">Epoch</span> <span class="mi">15</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.6388</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.4296</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.6752</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.4226</span>

<span class="n">Epoch</span> <span class="mi">20</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.6368</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.4325</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.6720</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.4240</span>

<span class="n">Training</span> <span class="n">complete</span> <span class="ow">in</span> <span class="mi">42</span><span class="n">m</span> <span class="mi">23</span><span class="n">s</span>
<span class="n">Best</span> <span class="n">val</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.429600</span>
</pre></div>
</div>
<img alt="../_images/dl_transfer-learning_cifar10-ants-bees_pytorch_11_1.png" src="../_images/dl_transfer-learning_cifar10-ants-bees_pytorch_11_1.png" />
<p>Adam optimizer</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_conv</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model_conv</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

<span class="c1"># Parameters of newly constructed modules have requires_grad=True by default</span>
<span class="n">num_ftrs</span> <span class="o">=</span> <span class="n">model_conv</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">in_features</span>
<span class="n">model_conv</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_ftrs</span><span class="p">,</span> <span class="n">D_out</span><span class="p">)</span>

<span class="n">model_conv</span> <span class="o">=</span> <span class="n">model_conv</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="c1"># Observe that only parameters of final layer are being optimized as</span>
<span class="c1"># opposed to before.</span>
<span class="n">optimizer_conv</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model_conv</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>

<span class="c1"># Decay LR by a factor of 0.1 every 7 epochs</span>
<span class="n">exp_lr_scheduler</span> <span class="o">=</span> <span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer_conv</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="n">model</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">accuracies</span> <span class="o">=</span> <span class="n">train_val_model</span><span class="p">(</span><span class="n">model_conv</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer_conv</span><span class="p">,</span>
    <span class="n">exp_lr_scheduler</span><span class="p">,</span> <span class="n">dataloaders</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">log_interval</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">epochs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">losses</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">losses</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span> <span class="s1">&#39;-b&#39;</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">losses</span><span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">],</span> <span class="s1">&#39;--r&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">---------------------------------------------------------------------------</span>

<span class="ne">TypeError</span>                                 <span class="n">Traceback</span> <span class="p">(</span><span class="n">most</span> <span class="n">recent</span> <span class="n">call</span> <span class="n">last</span><span class="p">)</span>

<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">7</span><span class="o">-</span><span class="n">dde92868b554</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
     <span class="mi">19</span>
     <span class="mi">20</span> <span class="n">model</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">accuracies</span> <span class="o">=</span> <span class="n">train_val_model</span><span class="p">(</span><span class="n">model_conv</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer_conv</span><span class="p">,</span>
<span class="o">---&gt;</span> <span class="mi">21</span>     <span class="n">exp_lr_scheduler</span><span class="p">,</span> <span class="n">dataloaders</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">log_interval</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
     <span class="mi">22</span>
     <span class="mi">23</span> <span class="n">epochs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">losses</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]))</span>


<span class="ne">TypeError</span><span class="p">:</span> <span class="n">train_val_model</span><span class="p">()</span> <span class="n">got</span> <span class="n">multiple</span> <span class="n">values</span> <span class="k">for</span> <span class="n">argument</span> <span class="s1">&#39;num_epochs&#39;</span>
</pre></div>
</div>
</section>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">Statistics and Machine Learning in Python</a></h1>








<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../introduction/python_ecosystem.html">Python ecosystem for data-science</a></li>
<li class="toctree-l1"><a class="reference internal" href="../introduction/machine_learning.html">Introduction to Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../introduction/machine_learning.html#data-analysis-methodology">Data analysis methodology</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html">Import libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#basic-operations">Basic operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#data-types">Data types</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#execution-control-statements">Execution control statements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#list-comprehensions-iterators-etc">List comprehensions, iterators, etc.</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#functions">Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#regular-expression">Regular expression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#system-programming">System programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#scripts-and-argument-parsing">Scripts and argument parsing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#networking">Networking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#modules-and-packages">Modules and packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#object-oriented-programming-oop">Object Oriented Programming (OOP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#style-guide-for-python-programming">Style guide for Python programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#documenting">Documenting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#exercises">Exercises</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/scipy_numpy.html">Numpy: arrays and matrices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/scipy_pandas.html">Pandas: data manipulation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scientific_python/scipy_matplotlib.html">Data visualization: matplotlib &amp; seaborn</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../statistics/stat_univ.html">Univariate statistics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/stat_univ_lab_brain-volume.html">Lab: Brain volumes study</a></li>
<li class="toctree-l1"><a class="reference internal" href="../statistics/stat_multiv.html">Multivariate statistics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../statistics/time_series.html">Time series in python</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../machine_learning/decomposition.html">Linear dimension reduction and feature extraction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../machine_learning/manifold.html">Manifold learning: non-linear dimension reduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../machine_learning/clustering.html">Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../machine_learning/linear_regression.html">Linear models for regression problems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../machine_learning/linear_classification.html">Linear models for classification problems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/ml_supervized_nonlinear.html">Non-linear models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/ml_resampling.html">Resampling methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../machine_learning/ensemble_learning.html">Ensemble learning: bagging, boosting and stacking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimization/optim_gradient_descent.html">Gradient descent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/ml_lab_face_recognition.html">Lab: Faces recognition using various learning models</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="dl_backprop_numpy-pytorch-sklearn.html">Backpropagation</a></li>
<li class="toctree-l1"><a class="reference internal" href="dl_mlp_mnist_pytorch.html">Multilayer Perceptron (MLP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dl_cnn_cifar10_pytorch.html">Convolutional neural network</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Transfer Learning Tutorial</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#training-function">Training function</a></li>
<li class="toctree-l2"><a class="reference internal" href="#cifar-10-dataset">CIFAR-10 dataset</a></li>
</ul>
</li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="dl_cnn_cifar10_pytorch.html" title="previous chapter">Convolutional neural network</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, Edouard Duchesnay, NeuroSpin CEA Université Paris-Saclay, France.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.0.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/deep_learning/dl_transfer-learning_cifar10-ants-bees_pytorch.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>