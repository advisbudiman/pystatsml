
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Multilayer Perceptron (MLP) &#8212; Statistics and Machine Learning in Python 0.5 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="search" type="application/opensearchdescription+xml"
          title="Search within Statistics and Machine Learning in Python 0.5 documentation"
          href="../_static/opensearch.xml"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Convolutional neural network" href="dl_cnn_cifar10_pytorch.html" />
    <link rel="prev" title="Backpropagation" href="dl_backprop_numpy-pytorch-sklearn.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="multilayer-perceptron-mlp">
<h1>Multilayer Perceptron (MLP)<a class="headerlink" href="#multilayer-perceptron-mlp" title="Permalink to this headline">¶</a></h1>
<section id="course-outline">
<h2>Course outline:<a class="headerlink" href="#course-outline" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li><p>Recall of linear classifier</p></li>
<li><p>MLP with scikit-learn</p></li>
<li><p>MLP with pytorch</p></li>
<li><p>Test several MLP architectures</p></li>
<li><p>Limits of MLP</p></li>
</ol>
<p>Sources:</p>
<p>Deep learning</p>
<ul class="simple">
<li><p><a class="reference external" href="http://cs231n.stanford.edu/">cs231n.stanford.edu</a></p></li>
</ul>
<p>Pytorch</p>
<ul class="simple">
<li><p><a class="reference external" href="https://pytorch.org/tutorials/">WWW tutorials</a></p></li>
<li><p><a class="reference external" href="https://github.com/pytorch/tutorials">github tutorials</a></p></li>
<li><p><a class="reference external" href="https://github.com/pytorch/examples">github examples</a></p></li>
</ul>
<p>MNIST and pytorch:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://nextjournal.com/gkoehler/pytorch-mnist">MNIST
nextjournal.com/gkoehler/pytorch-mnist</a></p></li>
<li><p><a class="reference external" href="https://github.com/pytorch/examples/tree/master/mnist">MNIST
github/pytorch/examples</a></p></li>
<li><p><a class="reference external" href="https://www.kaggle.com/sdelecourt/cnn-with-pytorch-for-mnist">MNIST
kaggle</a></p></li>
</ul>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">lr_scheduler</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">models</span>
<span class="c1">#</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Device configuration</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cpu&#39;</span> <span class="c1"># Force CPU</span>
<span class="nb">print</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cpu</span>
</pre></div>
</div>
<p>Hyperparameters</p>
</section>
<section id="dataset-mnist-handwritten-digit-recognition">
<h2>Dataset: MNIST Handwritten Digit Recognition<a class="headerlink" href="#dataset-mnist-handwritten-digit-recognition" title="Permalink to this headline">¶</a></h2>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="n">WD</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">Path</span><span class="o">.</span><span class="n">home</span><span class="p">(),</span> <span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="s2">&quot;pystatml&quot;</span><span class="p">,</span> <span class="s2">&quot;dl_mnist_pytorch&quot;</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">WD</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="n">WD</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Working dir is:&quot;</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">())</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="s2">&quot;models&quot;</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">load_mnist</span><span class="p">(</span><span class="n">batch_size_train</span><span class="p">,</span> <span class="n">batch_size_test</span><span class="p">):</span>

    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                       <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
                           <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                           <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">,))</span> <span class="c1"># Mean and Std of the MNIST dataset</span>
                       <span class="p">])),</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size_train</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">val_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">,))</span> <span class="c1"># Mean and Std of the MNIST dataset</span>
        <span class="p">])),</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size_test</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span>


<span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span> <span class="o">=</span> <span class="n">load_mnist</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">10000</span><span class="p">)</span>

<span class="n">dataloaders</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">train</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">val</span><span class="o">=</span><span class="n">val_loader</span><span class="p">)</span>

<span class="c1"># Info about the dataset</span>
<span class="n">D_in</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">dataloaders</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
<span class="n">D_out</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloaders</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Datasets shapes:&quot;</span><span class="p">,</span> <span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">dataloaders</span><span class="p">[</span><span class="n">x</span><span class="p">]</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;val&#39;</span><span class="p">]})</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;N input features:&quot;</span><span class="p">,</span> <span class="n">D_in</span><span class="p">,</span> <span class="s2">&quot;Output classes:&quot;</span><span class="p">,</span> <span class="n">D_out</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Working</span> <span class="nb">dir</span> <span class="ow">is</span><span class="p">:</span> <span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">ed203246</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">pystatml</span><span class="o">/</span><span class="n">dl_mnist_pytorch</span>
<span class="n">Datasets</span> <span class="n">shapes</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;train&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">60000</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">]),</span> <span class="s1">&#39;val&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">])}</span>
<span class="n">N</span> <span class="nb">input</span> <span class="n">features</span><span class="p">:</span> <span class="mi">784</span> <span class="n">Output</span> <span class="n">classes</span><span class="p">:</span> <span class="mi">10</span>
</pre></div>
</div>
<p>Now let’s take a look at some mini-batches examples.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">example_data</span><span class="p">,</span> <span class="n">example_targets</span><span class="p">)</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train batch:&quot;</span><span class="p">,</span> <span class="n">example_data</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">example_targets</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">example_data</span><span class="p">,</span> <span class="n">example_targets</span><span class="p">)</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">val_loader</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Val batch:&quot;</span><span class="p">,</span> <span class="n">example_data</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">example_targets</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Train</span> <span class="n">batch</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">64</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">])</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">64</span><span class="p">])</span>
<span class="n">Val</span> <span class="n">batch</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">])</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10000</span><span class="p">])</span>
</pre></div>
</div>
<p>So one test data batch is a tensor of shape: . This means we have 1000
examples of 28x28 pixels in grayscale (i.e. no rgb channels, hence the
one). We can plot some of them using matplotlib.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">show_data_label_prediction</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)):</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span> <span class="k">if</span> <span class="n">y_pred</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">y_pred</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">)):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="o">*</span><span class="n">shape</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;True: </span><span class="si">{}</span><span class="s2"> Pred: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_true</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([])</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([])</span>

<span class="n">show_data_label_prediction</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">example_data</span><span class="p">,</span> <span class="n">y_true</span><span class="o">=</span><span class="n">example_targets</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
<img alt="../_images/dl_mlp_mnist_pytorch_8_0.png" src="../_images/dl_mlp_mnist_pytorch_8_0.png" />
</section>
<section id="recall-of-linear-classifier">
<h2>Recall of linear classifier<a class="headerlink" href="#recall-of-linear-classifier" title="Permalink to this headline">¶</a></h2>
<section id="binary-logistic-regression">
<h3>Binary logistic regression<a class="headerlink" href="#binary-logistic-regression" title="Permalink to this headline">¶</a></h3>
<p>1 neuron as output layer</p>
<div class="math notranslate nohighlight">
\[f(x) = \sigma(x^{T} w)\]</div>
</section>
<section id="softmax-classifier-multinomial-logistic-regression">
<h3>Softmax Classifier (Multinomial Logistic Regression)<a class="headerlink" href="#softmax-classifier-multinomial-logistic-regression" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Input <span class="math notranslate nohighlight">\(x\)</span>: a vector of dimension <span class="math notranslate nohighlight">\((0)\)</span> (layer 0).</p></li>
<li><p>Ouput <span class="math notranslate nohighlight">\(f(x)\)</span> a vector of <span class="math notranslate nohighlight">\((1)\)</span> (layer 1) possible labels</p></li>
</ul>
<p>The model as <span class="math notranslate nohighlight">\((1)\)</span> neurons as output layer</p>
<div class="math notranslate nohighlight">
\[f(x) = \text{softmax}(x^{T} W + b)\]</div>
<p>Where <span class="math notranslate nohighlight">\(W\)</span> is a <span class="math notranslate nohighlight">\((0) \times (1)\)</span> of coefficients and
<span class="math notranslate nohighlight">\(b\)</span> is a <span class="math notranslate nohighlight">\((1)\)</span>-dimentional vector of bias.</p>
<p>MNIST classfification using multinomial logistic</p>
<p><a class="reference external" href="https://notebooks.azure.com/cntk/projects/edxdle/html/Lab2_LogisticRegression.ipynb">source: Logistic regression
MNIST</a></p>
<p>Here we fit a multinomial logistic regression with L2 penalty on a
subset of the MNIST digits classification task.</p>
<p><a class="reference external" href="https://scikit-learn.org/stable/auto_examples/linear_model/plot_sparse_logistic_regression_mnist.html">source:
scikit-learn.org</a></p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span> <span class="o">=</span> <span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="c1">#print(X_train.shape)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">X_test</span> <span class="o">=</span> <span class="n">val_loader</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">val_loader</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="mi">60000</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span> <span class="p">(</span><span class="mi">60000</span><span class="p">,)</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1">#from sklearn.datasets import fetch_openml</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="c1">#from sklearn.model_selection import train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">check_random_state</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Turn up tolerance for faster convergence</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mf">50.</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s1">&#39;multinomial&#39;</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;sag&#39;</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1">#sparsity = np.mean(clf.coef_ == 0) * 100</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test score with penalty: </span><span class="si">%.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">score</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Test</span> <span class="n">score</span> <span class="k">with</span> <span class="n">penalty</span><span class="p">:</span> <span class="mf">0.8997</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">coef</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">coef</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">l1_plot</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">l1_plot</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">coef</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">,</span>
                   <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">RdBu</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=-</span><span class="n">scale</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>
    <span class="n">l1_plot</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(())</span>
    <span class="n">l1_plot</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(())</span>
    <span class="n">l1_plot</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Class </span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Classification vector for...&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/dl_mlp_mnist_pytorch_12_0.png" src="../_images/dl_mlp_mnist_pytorch_12_0.png" />
</section>
</section>
<section id="model-two-layer-mlp">
<h2>Model: Two Layer MLP<a class="headerlink" href="#model-two-layer-mlp" title="Permalink to this headline">¶</a></h2>
<section id="mlp-with-scikit-learn">
<h3>MLP with Scikit-learn<a class="headerlink" href="#mlp-with-scikit-learn" title="Permalink to this headline">¶</a></h3>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPClassifier</span>

<span class="n">mlp</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="p">),</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
                    <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;sgd&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">learning_rate_init</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>

<span class="n">mlp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">mlp</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">mlp</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Coef shape=&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">mlp</span><span class="o">.</span><span class="n">coefs_</span><span class="p">))</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="c1"># use global min / max to ensure all weights are shown on the same scale</span>
<span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span> <span class="o">=</span> <span class="n">mlp</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">mlp</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
<span class="k">for</span> <span class="n">coef</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">mlp</span><span class="o">.</span><span class="n">coefs_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">axes</span><span class="o">.</span><span class="n">ravel</span><span class="p">()):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">coef</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">gray</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mf">.5</span> <span class="o">*</span> <span class="n">vmin</span><span class="p">,</span>
               <span class="n">vmax</span><span class="o">=</span><span class="mf">.5</span> <span class="o">*</span> <span class="n">vmax</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(())</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(())</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Iteration</span> <span class="mi">1</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.28828673</span>
<span class="n">Iteration</span> <span class="mi">2</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.13388073</span>
<span class="n">Iteration</span> <span class="mi">3</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.09366379</span>
<span class="n">Iteration</span> <span class="mi">4</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.07317648</span>
<span class="n">Iteration</span> <span class="mi">5</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.05340251</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">ed203246</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.7</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">sklearn</span><span class="o">/</span><span class="n">neural_network</span><span class="o">/</span><span class="n">_multilayer_perceptron</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">585</span><span class="p">:</span> <span class="n">ConvergenceWarning</span><span class="p">:</span> <span class="n">Stochastic</span> <span class="n">Optimizer</span><span class="p">:</span> <span class="n">Maximum</span> <span class="n">iterations</span> <span class="p">(</span><span class="mi">5</span><span class="p">)</span> <span class="n">reached</span> <span class="ow">and</span> <span class="n">the</span> <span class="n">optimization</span> <span class="n">hasn</span><span class="s1">&#39;t converged yet.</span>
  <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span> <span class="n">ConvergenceWarning</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Training</span> <span class="nb">set</span> <span class="n">score</span><span class="p">:</span> <span class="mf">0.989067</span>
<span class="n">Test</span> <span class="nb">set</span> <span class="n">score</span><span class="p">:</span> <span class="mf">0.971900</span>
<span class="n">Coef</span> <span class="n">shape</span><span class="o">=</span> <span class="mi">2</span>
</pre></div>
</div>
<img alt="../_images/dl_mlp_mnist_pytorch_14_3.png" src="../_images/dl_mlp_mnist_pytorch_14_3.png" />
</section>
<section id="mlp-with-pytorch">
<h3>MLP with pytorch<a class="headerlink" href="#mlp-with-pytorch" title="Permalink to this headline">¶</a></h3>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">TwoLayerMLP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_in</span><span class="p">,</span> <span class="n">d_hidden</span><span class="p">,</span> <span class="n">d_out</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TwoLayerMLP</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d_in</span> <span class="o">=</span> <span class="n">d_in</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">linear1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_hidden</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_hidden</span><span class="p">,</span> <span class="n">d_out</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_in</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear1</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear2</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<section id="train-the-model">
<h4>Train the Model<a class="headerlink" href="#train-the-model" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>First we want to make sure our network is in training mode.</p></li>
<li><p>Iterate over epochs</p></li>
<li><p>Alternate train and validation dataset</p></li>
<li><p>Iterate over all training/val data once per epoch. Loading the
individual batches is handled by the DataLoader.</p></li>
<li><p>Set the gradients to zero using <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code> since
PyTorch by default accumulates gradients.</p></li>
<li><p>Forward pass:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">model(inputs)</span></code>: Produce the output of our network.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">torch.max(outputs,</span> <span class="pre">1)</span></code>: softmax predictions.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">criterion(outputs,</span> <span class="pre">labels)</span></code>: loss between the output and the
ground truth label.</p></li>
</ul>
</li>
<li><p>In training mode, backward pass <code class="docutils literal notranslate"><span class="pre">backward()</span></code>: collect a new set of
gradients which we propagate back into each of the network’s
parameters using <code class="docutils literal notranslate"><span class="pre">optimizer.step()</span></code>.</p></li>
<li><p>We’ll also keep track of the progress with some printouts. In order
to create a nice training curve later on we also create two lists for
saving training and testing losses. On the x-axis we want to display
the number of training examples the network has seen during training.</p></li>
<li><p>Save model state: Neural network modules as well as optimizers have
the ability to save and load their internal state using
<code class="docutils literal notranslate"><span class="pre">.state_dict()</span></code>. With this we can continue training from previously
saved state dicts if needed - we’d just need to call
<code class="docutils literal notranslate"><span class="pre">.load_state_dict(state_dict)</span></code>.</p></li>
</ul>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># %load train_val_model.py</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># %load train_val_model.py</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">copy</span>


<span class="k">def</span> <span class="nf">train_val_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloaders</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span>
        <span class="n">scheduler</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">log_interval</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">since</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="n">best_model_wts</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
    <span class="n">best_acc</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="c1"># Store losses and accuracies accross epochs</span>
    <span class="n">losses</span><span class="p">,</span> <span class="n">accuracies</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">train</span><span class="o">=</span><span class="p">[],</span> <span class="n">val</span><span class="o">=</span><span class="p">[]),</span> <span class="nb">dict</span><span class="p">(</span><span class="n">train</span><span class="o">=</span><span class="p">[],</span> <span class="n">val</span><span class="o">=</span><span class="p">[])</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">log_interval</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">log_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">num_epochs</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>

        <span class="c1"># Each epoch has a training and validation phase</span>
        <span class="k">for</span> <span class="n">phase</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;val&#39;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s1">&#39;train&#39;</span><span class="p">:</span>
                <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>  <span class="c1"># Set model to training mode</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>   <span class="c1"># Set model to evaluate mode</span>

            <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="n">running_corrects</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="c1"># Iterate over data.</span>
            <span class="n">nsamples</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">dataloaders</span><span class="p">[</span><span class="n">phase</span><span class="p">]:</span>
                <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">nsamples</span> <span class="o">+=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

                <span class="c1"># zero the parameter gradients</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

                <span class="c1"># forward</span>
                <span class="c1"># track history if only in train</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">set_grad_enabled</span><span class="p">(</span><span class="n">phase</span> <span class="o">==</span> <span class="s1">&#39;train&#39;</span><span class="p">):</span>
                    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
                    <span class="n">_</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

                    <span class="c1"># backward + optimize only if in training phase</span>
                    <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s1">&#39;train&#39;</span><span class="p">:</span>
                        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

                <span class="c1"># statistics</span>
                <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">inputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">running_corrects</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">preds</span> <span class="o">==</span> <span class="n">labels</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">scheduler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">phase</span> <span class="o">==</span> <span class="s1">&#39;train&#39;</span><span class="p">:</span>
                <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="c1">#nsamples = dataloaders[phase].dataset.data.shape[0]</span>
            <span class="n">epoch_loss</span> <span class="o">=</span> <span class="n">running_loss</span> <span class="o">/</span> <span class="n">nsamples</span>
            <span class="n">epoch_acc</span> <span class="o">=</span> <span class="n">running_corrects</span><span class="o">.</span><span class="n">double</span><span class="p">()</span> <span class="o">/</span> <span class="n">nsamples</span>

            <span class="n">losses</span><span class="p">[</span><span class="n">phase</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch_loss</span><span class="p">)</span>
            <span class="n">accuracies</span><span class="p">[</span><span class="n">phase</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch_acc</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">log_interval</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">log_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1"> Loss: </span><span class="si">{:.4f}</span><span class="s1"> Acc: </span><span class="si">{:.2f}</span><span class="s1">%&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">phase</span><span class="p">,</span> <span class="n">epoch_loss</span><span class="p">,</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">epoch_acc</span><span class="p">))</span>

            <span class="c1"># deep copy the model</span>
            <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s1">&#39;val&#39;</span> <span class="ow">and</span> <span class="n">epoch_acc</span> <span class="o">&gt;</span> <span class="n">best_acc</span><span class="p">:</span>
                <span class="n">best_acc</span> <span class="o">=</span> <span class="n">epoch_acc</span>
                <span class="n">best_model_wts</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">log_interval</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">log_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">()</span>

    <span class="n">time_elapsed</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">since</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training complete in </span><span class="si">{:.0f}</span><span class="s1">m </span><span class="si">{:.0f}</span><span class="s1">s&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">time_elapsed</span> <span class="o">//</span> <span class="mi">60</span><span class="p">,</span> <span class="n">time_elapsed</span> <span class="o">%</span> <span class="mi">60</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Best val Acc: </span><span class="si">{:.2f}</span><span class="s1">%&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">best_acc</span><span class="p">))</span>

    <span class="c1"># load best model weights</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">best_model_wts</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">accuracies</span>
</pre></div>
</div>
<p>Run one epoch and save the model</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">TwoLayerMLP</span><span class="p">(</span><span class="n">D_in</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">D_out</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">is_cuda</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>

<span class="c1"># Explore the model</span>
<span class="k">for</span> <span class="n">parameter</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">parameter</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total number of parameters =&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">parameter</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">parameter</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()]))</span>

<span class="n">model</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">accuracies</span> <span class="o">=</span> <span class="n">train_val_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloaders</span><span class="p">,</span>
                       <span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">log_interval</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">is_cuda</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">&#39;models/mod-</span><span class="si">%s</span><span class="s1">.pth&#39;</span> <span class="o">%</span> <span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kc">False</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">50</span><span class="p">,</span> <span class="mi">784</span><span class="p">])</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">50</span><span class="p">])</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">])</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10</span><span class="p">])</span>
<span class="n">Total</span> <span class="n">number</span> <span class="n">of</span> <span class="n">parameters</span> <span class="o">=</span> <span class="mi">39760</span>
<span class="n">Epoch</span> <span class="mi">0</span><span class="o">/</span><span class="mi">0</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.4431</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">87.93</span><span class="o">%</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.3062</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">91.21</span><span class="o">%</span>

<span class="n">Training</span> <span class="n">complete</span> <span class="ow">in</span> <span class="mi">0</span><span class="n">m</span> <span class="mi">7</span><span class="n">s</span>
<span class="n">Best</span> <span class="n">val</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">91.21</span><span class="o">%</span>
<span class="kc">False</span>
</pre></div>
</div>
<p>Use the model to make new predictions. Consider the device, ie, load
data on device <code class="docutils literal notranslate"><span class="pre">example_data.to(device)</span></code> from prediction, then move
back to cpu <code class="docutils literal notranslate"><span class="pre">example_data.cpu()</span></code>.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">example_data</span><span class="p">,</span> <span class="n">example_targets</span><span class="p">)</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">val_loader</span><span class="p">))</span>
<span class="n">example_data</span> <span class="o">=</span> <span class="n">example_data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
  <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">example_data</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>

<span class="n">example_data</span> <span class="o">=</span> <span class="n">example_data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>

<span class="c1"># print(output.is_cuda)</span>

<span class="c1"># Softmax predictions</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Output shape=&quot;</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;label shape=&quot;</span><span class="p">,</span> <span class="n">preds</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy = </span><span class="si">{:.2f}</span><span class="s2">%&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">((</span><span class="n">example_targets</span> <span class="o">==</span> <span class="n">preds</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="mf">100.</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">example_targets</span><span class="p">)))</span>

<span class="n">show_data_label_prediction</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">example_data</span><span class="p">,</span> <span class="n">y_true</span><span class="o">=</span><span class="n">example_targets</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">preds</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Output</span> <span class="n">shape</span><span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span> <span class="n">label</span> <span class="n">shape</span><span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10000</span><span class="p">])</span>
<span class="n">Accuracy</span> <span class="o">=</span> <span class="mf">91.21</span><span class="o">%</span>
</pre></div>
</div>
<img alt="../_images/dl_mlp_mnist_pytorch_23_1.png" src="../_images/dl_mlp_mnist_pytorch_23_1.png" />
<p>Plot missclassified samples</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">errors</span> <span class="o">=</span> <span class="n">example_targets</span> <span class="o">!=</span> <span class="n">preds</span>
<span class="c1">#print(errors, np.where(errors))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Nb errors = </span><span class="si">{}</span><span class="s2">, (Error rate = </span><span class="si">{:.2f}</span><span class="s2">%)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">errors</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">errors</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">errors</span><span class="p">)))</span>
<span class="n">err_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">errors</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">show_data_label_prediction</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">example_data</span><span class="p">[</span><span class="n">err_idx</span><span class="p">],</span> <span class="n">y_true</span><span class="o">=</span><span class="n">example_targets</span><span class="p">[</span><span class="n">err_idx</span><span class="p">],</span>
                           <span class="n">y_pred</span><span class="o">=</span><span class="n">preds</span><span class="p">[</span><span class="n">err_idx</span><span class="p">],</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Nb</span> <span class="n">errors</span> <span class="o">=</span> <span class="mi">879</span><span class="p">,</span> <span class="p">(</span><span class="n">Error</span> <span class="n">rate</span> <span class="o">=</span> <span class="mf">8.79</span><span class="o">%</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../_images/dl_mlp_mnist_pytorch_25_1.png" src="../_images/dl_mlp_mnist_pytorch_25_1.png" />
</section>
<section id="continue-training-from-checkpoints-reload-the-model-and-run-10-more-epochs">
<h4>Continue training from checkpoints: reload the model and run 10 more epochs<a class="headerlink" href="#continue-training-from-checkpoints-reload-the-model-and-run-10-more-epochs" title="Permalink to this headline">¶</a></h4>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">TwoLayerMLP</span><span class="p">(</span><span class="n">D_in</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">D_out</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;models/mod-</span><span class="si">%s</span><span class="s1">.pth&#39;</span> <span class="o">%</span> <span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>

<span class="n">model</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">accuracies</span> <span class="o">=</span> <span class="n">train_val_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloaders</span><span class="p">,</span>
                       <span class="n">num_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">log_interval</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">losses</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span> <span class="s1">&#39;-b&#39;</span><span class="p">,</span> <span class="n">losses</span><span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">],</span> <span class="s1">&#39;--r&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Epoch</span> <span class="mi">0</span><span class="o">/</span><span class="mi">9</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.3096</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">91.11</span><span class="o">%</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2897</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">91.65</span><span class="o">%</span>

<span class="n">Epoch</span> <span class="mi">2</span><span class="o">/</span><span class="mi">9</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2853</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">92.03</span><span class="o">%</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2833</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">92.04</span><span class="o">%</span>

<span class="n">Epoch</span> <span class="mi">4</span><span class="o">/</span><span class="mi">9</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2749</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">92.36</span><span class="o">%</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2757</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">92.01</span><span class="o">%</span>

<span class="n">Epoch</span> <span class="mi">6</span><span class="o">/</span><span class="mi">9</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2692</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">92.51</span><span class="o">%</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2741</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">92.29</span><span class="o">%</span>

<span class="n">Epoch</span> <span class="mi">8</span><span class="o">/</span><span class="mi">9</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2651</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">92.61</span><span class="o">%</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2715</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">92.32</span><span class="o">%</span>

<span class="n">Training</span> <span class="n">complete</span> <span class="ow">in</span> <span class="mi">1</span><span class="n">m</span> <span class="mi">14</span><span class="n">s</span>
<span class="n">Best</span> <span class="n">val</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">92.32</span><span class="o">%</span>
</pre></div>
</div>
<img alt="../_images/dl_mlp_mnist_pytorch_27_1.png" src="../_images/dl_mlp_mnist_pytorch_27_1.png" />
</section>
</section>
</section>
<section id="test-several-mlp-architectures">
<h2>Test several MLP architectures<a class="headerlink" href="#test-several-mlp-architectures" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Define a <code class="docutils literal notranslate"><span class="pre">MultiLayerMLP([D_in,</span> <span class="pre">512,</span> <span class="pre">256,</span> <span class="pre">128,</span> <span class="pre">64,</span> <span class="pre">D_out])</span></code> class
that take the size of the layers as parameters of the constructor.</p></li>
<li><p>Add some non-linearity with relu acivation function</p></li>
</ul>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MLP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_layer</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MLP</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d_layer</span> <span class="o">=</span> <span class="n">d_layer</span>
        <span class="n">layer_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_layer</span><span class="p">[</span><span class="n">l</span><span class="p">],</span> <span class="n">d_layer</span><span class="p">[</span><span class="n">l</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">d_layer</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linears</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">layer_list</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_layer</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="c1"># relu(Wl x) for all hidden layer</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">linears</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">layer</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
        <span class="c1"># softmax(Wl x) for output layer</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linears</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">](</span><span class="n">X</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="n">D_in</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">D_out</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>

<span class="n">model</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">accuracies</span> <span class="o">=</span> <span class="n">train_val_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloaders</span><span class="p">,</span>
                       <span class="n">num_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">log_interval</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">losses</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span> <span class="s1">&#39;-b&#39;</span><span class="p">,</span> <span class="n">losses</span><span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">],</span> <span class="s1">&#39;--r&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Epoch</span> <span class="mi">0</span><span class="o">/</span><span class="mi">9</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.1216</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">66.19</span><span class="o">%</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.3347</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">90.71</span><span class="o">%</span>

<span class="n">Epoch</span> <span class="mi">2</span><span class="o">/</span><span class="mi">9</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1744</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">94.94</span><span class="o">%</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1461</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">95.52</span><span class="o">%</span>

<span class="n">Epoch</span> <span class="mi">4</span><span class="o">/</span><span class="mi">9</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0979</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">97.14</span><span class="o">%</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1089</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">96.49</span><span class="o">%</span>

<span class="n">Epoch</span> <span class="mi">6</span><span class="o">/</span><span class="mi">9</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0635</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">98.16</span><span class="o">%</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0795</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">97.68</span><span class="o">%</span>

<span class="n">Epoch</span> <span class="mi">8</span><span class="o">/</span><span class="mi">9</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0422</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">98.77</span><span class="o">%</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0796</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">97.54</span><span class="o">%</span>

<span class="n">Training</span> <span class="n">complete</span> <span class="ow">in</span> <span class="mi">1</span><span class="n">m</span> <span class="mi">53</span><span class="n">s</span>
<span class="n">Best</span> <span class="n">val</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">97.68</span><span class="o">%</span>
</pre></div>
</div>
<img alt="../_images/dl_mlp_mnist_pytorch_30_1.png" src="../_images/dl_mlp_mnist_pytorch_30_1.png" />
</section>
<section id="reduce-the-size-of-training-dataset">
<h2>Reduce the size of training dataset<a class="headerlink" href="#reduce-the-size-of-training-dataset" title="Permalink to this headline">¶</a></h2>
<p>Reduce the size of the training dataset by considering only <code class="docutils literal notranslate"><span class="pre">10</span></code>
minibatche for size<code class="docutils literal notranslate"><span class="pre">16</span></code>.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span> <span class="o">=</span> <span class="n">load_mnist</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

<span class="n">train_size</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">*</span> <span class="mi">16</span>

<span class="c1"># Stratified sub-sampling</span>
<span class="n">targets</span> <span class="o">=</span> <span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">nclasses</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">targets</span><span class="p">))</span>

<span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">targets</span> <span class="o">==</span> <span class="n">lab</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">int</span><span class="p">(</span><span class="n">train_size</span> <span class="o">/</span> <span class="n">nclasses</span><span class="p">),</span><span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">lab</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="n">targets</span><span class="p">)])</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">sampler</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">SubsetRandomSampler</span><span class="p">(</span><span class="n">indices</span><span class="p">))</span>

<span class="c1"># Check train subsampling</span>
<span class="n">train_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">labels</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train size=&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_labels</span><span class="p">),</span> <span class="s2">&quot; Train label count=&quot;</span><span class="p">,</span> <span class="p">{</span><span class="n">lab</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">train_labels</span> <span class="o">==</span> <span class="n">lab</span><span class="p">)</span> <span class="k">for</span> <span class="n">lab</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="n">train_labels</span><span class="p">)})</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Batch sizes=&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">inputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">])</span>

<span class="c1"># Put together train and val</span>
<span class="n">dataloaders</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">train</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">val</span><span class="o">=</span><span class="n">val_loader</span><span class="p">)</span>

<span class="c1"># Info about the dataset</span>
<span class="n">D_in</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">dataloaders</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
<span class="n">D_out</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloaders</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Datasets shape&quot;</span><span class="p">,</span> <span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">dataloaders</span><span class="p">[</span><span class="n">x</span><span class="p">]</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;val&#39;</span><span class="p">]})</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;N input features&quot;</span><span class="p">,</span> <span class="n">D_in</span><span class="p">,</span> <span class="s2">&quot;N output&quot;</span><span class="p">,</span> <span class="n">D_out</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Train</span> <span class="n">size</span><span class="o">=</span> <span class="mi">160</span>  <span class="n">Train</span> <span class="n">label</span> <span class="n">count</span><span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">4</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">7</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">8</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">9</span><span class="p">:</span> <span class="mi">16</span><span class="p">}</span>
<span class="n">Batch</span> <span class="n">sizes</span><span class="o">=</span> <span class="p">[</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">]</span>
<span class="n">Datasets</span> <span class="n">shape</span> <span class="p">{</span><span class="s1">&#39;train&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">60000</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">]),</span> <span class="s1">&#39;val&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">])}</span>
<span class="n">N</span> <span class="nb">input</span> <span class="n">features</span> <span class="mi">784</span> <span class="n">N</span> <span class="n">output</span> <span class="mi">10</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="n">D_in</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">D_out</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>

<span class="n">model</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">accuracies</span> <span class="o">=</span> <span class="n">train_val_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloaders</span><span class="p">,</span>
                       <span class="n">num_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">log_interval</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">losses</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span> <span class="s1">&#39;-b&#39;</span><span class="p">,</span> <span class="n">losses</span><span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">],</span> <span class="s1">&#39;--r&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Epoch</span> <span class="mi">0</span><span class="o">/</span><span class="mi">99</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">2.3050</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">10.00</span><span class="o">%</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">2.3058</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">8.92</span><span class="o">%</span>

<span class="n">Epoch</span> <span class="mi">20</span><span class="o">/</span><span class="mi">99</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">2.2389</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">42.50</span><span class="o">%</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">2.2534</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">29.90</span><span class="o">%</span>

<span class="n">Epoch</span> <span class="mi">40</span><span class="o">/</span><span class="mi">99</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.9381</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">83.75</span><span class="o">%</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.1041</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">68.36</span><span class="o">%</span>

<span class="n">Epoch</span> <span class="mi">60</span><span class="o">/</span><span class="mi">99</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0533</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">100.00</span><span class="o">%</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.7823</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">76.69</span><span class="o">%</span>

<span class="n">Epoch</span> <span class="mi">80</span><span class="o">/</span><span class="mi">99</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0138</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">100.00</span><span class="o">%</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.8884</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">76.88</span><span class="o">%</span>

<span class="n">Training</span> <span class="n">complete</span> <span class="ow">in</span> <span class="mi">2</span><span class="n">m</span> <span class="mi">17</span><span class="n">s</span>
<span class="n">Best</span> <span class="n">val</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">77.08</span><span class="o">%</span>
</pre></div>
</div>
<img alt="../_images/dl_mlp_mnist_pytorch_33_1.png" src="../_images/dl_mlp_mnist_pytorch_33_1.png" />
<p>Use an opimizer with an adaptative learning rate: Adam</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="n">D_in</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">D_out</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>

<span class="n">model</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">accuracies</span> <span class="o">=</span> <span class="n">train_val_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloaders</span><span class="p">,</span>
                       <span class="n">num_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">log_interval</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">losses</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span> <span class="s1">&#39;-b&#39;</span><span class="p">,</span> <span class="n">losses</span><span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">],</span> <span class="s1">&#39;--r&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Epoch</span> <span class="mi">0</span><span class="o">/</span><span class="mi">99</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">2.2706</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">23.75</span><span class="o">%</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">2.1079</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">44.98</span><span class="o">%</span>

<span class="n">Epoch</span> <span class="mi">20</span><span class="o">/</span><span class="mi">99</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0012</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">100.00</span><span class="o">%</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.0338</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">78.23</span><span class="o">%</span>

<span class="n">Epoch</span> <span class="mi">40</span><span class="o">/</span><span class="mi">99</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0003</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">100.00</span><span class="o">%</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.1383</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">78.24</span><span class="o">%</span>

<span class="n">Epoch</span> <span class="mi">60</span><span class="o">/</span><span class="mi">99</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0002</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">100.00</span><span class="o">%</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.2075</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">78.17</span><span class="o">%</span>

<span class="n">Epoch</span> <span class="mi">80</span><span class="o">/</span><span class="mi">99</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0001</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">100.00</span><span class="o">%</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">1.2571</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">78.26</span><span class="o">%</span>

<span class="n">Training</span> <span class="n">complete</span> <span class="ow">in</span> <span class="mi">2</span><span class="n">m</span> <span class="mi">28</span><span class="n">s</span>
<span class="n">Best</span> <span class="n">val</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">78.35</span><span class="o">%</span>
</pre></div>
</div>
<img alt="../_images/dl_mlp_mnist_pytorch_35_1.png" src="../_images/dl_mlp_mnist_pytorch_35_1.png" />
</section>
<section id="run-mlp-on-cifar-10-dataset">
<h2>Run MLP on CIFAR-10 dataset<a class="headerlink" href="#run-mlp-on-cifar-10-dataset" title="Permalink to this headline">¶</a></h2>
<p>The CIFAR-10 dataset consists of 60000 32x32 colour images in 10
classes, with 6000 images per class. There are 50000 training images and
10000 test images.</p>
<p>The dataset is divided into five training batches and one test batch,
each with 10000 images. The test batch contains exactly 1000
randomly-selected images from each class. The training batches contain
the remaining images in random order, but some training batches may
contain more images from one class than another. Between them, the
training batches contain exactly 5000 images from each class.</p>
<div class="line-block">
<div class="line">Here are the classes in the dataset, as well as 10 random images from
each: - airplane</div>
<div class="line">- automobile</div>
<div class="line">- bird</div>
<div class="line">- cat</div>
<div class="line">- deer</div>
<div class="line">- dog</div>
<div class="line">- frog</div>
<div class="line">- horse</div>
<div class="line">- ship</div>
<div class="line">- truck</div>
</div>
<p>Load CIFAR-10 dataset</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="n">WD</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">Path</span><span class="o">.</span><span class="n">home</span><span class="p">(),</span> <span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="s2">&quot;pystatml&quot;</span><span class="p">,</span> <span class="s2">&quot;dl_cifar10_pytorch&quot;</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">WD</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="n">WD</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Working dir is:&quot;</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">())</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="s2">&quot;models&quot;</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>


<span class="c1"># Device configuration</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>

<span class="c1"># Hyper-parameters</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>

<span class="c1"># Image preprocessing modules</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Pad</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">RandomCrop</span><span class="p">(</span><span class="mi">32</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()])</span>

<span class="c1"># CIFAR-10 dataset</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;data/&#39;</span><span class="p">,</span>
                                             <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                             <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span>
                                             <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">val_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;data/&#39;</span><span class="p">,</span>
                                            <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                            <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">())</span>

<span class="c1"># Data loader</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>
                                           <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                                           <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">val_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">val_dataset</span><span class="p">,</span>
                                          <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                                          <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Put together train and val</span>
<span class="n">dataloaders</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">train</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">val</span><span class="o">=</span><span class="n">val_loader</span><span class="p">)</span>

<span class="c1"># Info about the dataset</span>
<span class="n">D_in</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">dataloaders</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
<span class="n">D_out</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">dataloaders</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">targets</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Datasets shape:&quot;</span><span class="p">,</span> <span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">dataloaders</span><span class="p">[</span><span class="n">x</span><span class="p">]</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;val&#39;</span><span class="p">]})</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;N input features:&quot;</span><span class="p">,</span> <span class="n">D_in</span><span class="p">,</span> <span class="s2">&quot;N output:&quot;</span><span class="p">,</span> <span class="n">D_out</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Working</span> <span class="nb">dir</span> <span class="ow">is</span><span class="p">:</span> <span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">ed203246</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">pystatml</span><span class="o">/</span><span class="n">dl_cifar10_pytorch</span>
<span class="n">Files</span> <span class="n">already</span> <span class="n">downloaded</span> <span class="ow">and</span> <span class="n">verified</span>
<span class="n">Datasets</span> <span class="n">shape</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;train&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">50000</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="s1">&#39;val&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">)}</span>
<span class="n">N</span> <span class="nb">input</span> <span class="n">features</span><span class="p">:</span> <span class="mi">3072</span> <span class="n">N</span> <span class="n">output</span><span class="p">:</span> <span class="mi">10</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="n">D_in</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">D_out</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>

<span class="n">model</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">accuracies</span> <span class="o">=</span> <span class="n">train_val_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloaders</span><span class="p">,</span>
                       <span class="n">num_epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">log_interval</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">losses</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span> <span class="s1">&#39;-b&#39;</span><span class="p">,</span> <span class="n">losses</span><span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">],</span> <span class="s1">&#39;--r&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">---------------------------------------------------------------------------</span>

<span class="ne">RuntimeError</span>                              <span class="n">Traceback</span> <span class="p">(</span><span class="n">most</span> <span class="n">recent</span> <span class="n">call</span> <span class="n">last</span><span class="p">)</span>

<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">36</span><span class="o">-</span><span class="mi">13724</span><span class="n">f7cb709</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="o">----&gt;</span> <span class="mi">1</span> <span class="n">model</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="n">D_in</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">D_out</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
      <span class="mi">2</span> <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
      <span class="mi">3</span> <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>
      <span class="mi">4</span>
      <span class="mi">5</span> <span class="n">model</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">accuracies</span> <span class="o">=</span> <span class="n">train_val_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">dataloaders</span><span class="p">,</span>


<span class="o">~/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.7</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">torch</span><span class="o">/</span><span class="n">nn</span><span class="o">/</span><span class="n">modules</span><span class="o">/</span><span class="n">module</span><span class="o">.</span><span class="n">py</span> <span class="ow">in</span> <span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="mi">424</span>             <span class="k">return</span> <span class="n">t</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span> <span class="k">if</span> <span class="n">t</span><span class="o">.</span><span class="n">is_floating_point</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span> <span class="n">non_blocking</span><span class="p">)</span>
    <span class="mi">425</span>
<span class="o">--&gt;</span> <span class="mi">426</span>         <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply</span><span class="p">(</span><span class="n">convert</span><span class="p">)</span>
    <span class="mi">427</span>
    <span class="mi">428</span>     <span class="k">def</span> <span class="nf">register_backward_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hook</span><span class="p">):</span>


<span class="o">~/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.7</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">torch</span><span class="o">/</span><span class="n">nn</span><span class="o">/</span><span class="n">modules</span><span class="o">/</span><span class="n">module</span><span class="o">.</span><span class="n">py</span> <span class="ow">in</span> <span class="n">_apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
    <span class="mi">200</span>     <span class="k">def</span> <span class="nf">_apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fn</span><span class="p">):</span>
    <span class="mi">201</span>         <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">():</span>
<span class="o">--&gt;</span> <span class="mi">202</span>             <span class="n">module</span><span class="o">.</span><span class="n">_apply</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
    <span class="mi">203</span>
    <span class="mi">204</span>         <span class="k">def</span> <span class="nf">compute_should_use_set_data</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">tensor_applied</span><span class="p">):</span>


<span class="o">~/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.7</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">torch</span><span class="o">/</span><span class="n">nn</span><span class="o">/</span><span class="n">modules</span><span class="o">/</span><span class="n">module</span><span class="o">.</span><span class="n">py</span> <span class="ow">in</span> <span class="n">_apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
    <span class="mi">200</span>     <span class="k">def</span> <span class="nf">_apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fn</span><span class="p">):</span>
    <span class="mi">201</span>         <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">():</span>
<span class="o">--&gt;</span> <span class="mi">202</span>             <span class="n">module</span><span class="o">.</span><span class="n">_apply</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
    <span class="mi">203</span>
    <span class="mi">204</span>         <span class="k">def</span> <span class="nf">compute_should_use_set_data</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">tensor_applied</span><span class="p">):</span>


<span class="o">~/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.7</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">torch</span><span class="o">/</span><span class="n">nn</span><span class="o">/</span><span class="n">modules</span><span class="o">/</span><span class="n">module</span><span class="o">.</span><span class="n">py</span> <span class="ow">in</span> <span class="n">_apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
    <span class="mi">222</span>                 <span class="c1"># `with torch.no_grad():`</span>
    <span class="mi">223</span>                 <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="o">--&gt;</span> <span class="mi">224</span>                     <span class="n">param_applied</span> <span class="o">=</span> <span class="n">fn</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
    <span class="mi">225</span>                 <span class="n">should_use_set_data</span> <span class="o">=</span> <span class="n">compute_should_use_set_data</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">param_applied</span><span class="p">)</span>
    <span class="mi">226</span>                 <span class="k">if</span> <span class="n">should_use_set_data</span><span class="p">:</span>


<span class="o">~/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.7</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">torch</span><span class="o">/</span><span class="n">nn</span><span class="o">/</span><span class="n">modules</span><span class="o">/</span><span class="n">module</span><span class="o">.</span><span class="n">py</span> <span class="ow">in</span> <span class="n">convert</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
    <span class="mi">422</span>
    <span class="mi">423</span>         <span class="k">def</span> <span class="nf">convert</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
<span class="o">--&gt;</span> <span class="mi">424</span>             <span class="k">return</span> <span class="n">t</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span> <span class="k">if</span> <span class="n">t</span><span class="o">.</span><span class="n">is_floating_point</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span> <span class="n">non_blocking</span><span class="p">)</span>
    <span class="mi">425</span>
    <span class="mi">426</span>         <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply</span><span class="p">(</span><span class="n">convert</span><span class="p">)</span>


<span class="ne">RuntimeError</span><span class="p">:</span> <span class="n">CUDA</span> <span class="n">error</span><span class="p">:</span> <span class="nb">all</span> <span class="n">CUDA</span><span class="o">-</span><span class="n">capable</span> <span class="n">devices</span> <span class="n">are</span> <span class="n">busy</span> <span class="ow">or</span> <span class="n">unavailable</span>
</pre></div>
</div>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">Statistics and Machine Learning in Python</a></h1>








<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../introduction/python_ecosystem.html">Python ecosystem for data-science</a></li>
<li class="toctree-l1"><a class="reference internal" href="../introduction/machine_learning.html">Introduction to Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../introduction/machine_learning.html#data-analysis-methodology">Data analysis methodology</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html">Import libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#basic-operations">Basic operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#data-types">Data types</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#execution-control-statements">Execution control statements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#list-comprehensions-iterators-etc">List comprehensions, iterators, etc.</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#functions">Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#regular-expression">Regular expression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#system-programming">System programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#scripts-and-argument-parsing">Scripts and argument parsing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#networking">Networking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#modules-and-packages">Modules and packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#object-oriented-programming-oop">Object Oriented Programming (OOP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#style-guide-for-python-programming">Style guide for Python programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#documenting">Documenting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#exercises">Exercises</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/scipy_numpy.html">Numpy: arrays and matrices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/scipy_pandas.html">Pandas: data manipulation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scientific_python/scipy_matplotlib.html">Data visualization: matplotlib &amp; seaborn</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../statistics/stat_univ.html">Univariate statistics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/stat_univ_lab_brain-volume.html">Lab: Brain volumes study</a></li>
<li class="toctree-l1"><a class="reference internal" href="../statistics/stat_multiv.html">Multivariate statistics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../statistics/time_series.html">Time series in python</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../machine_learning/decomposition.html">Linear dimension reduction and feature extraction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../machine_learning/manifold.html">Manifold learning: non-linear dimension reduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../machine_learning/clustering.html">Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../machine_learning/linear_regression.html">Linear models for regression problems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../machine_learning/linear_classification.html">Linear models for classification problems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/ml_supervized_nonlinear.html">Non-linear models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/ml_resampling.html">Resampling methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../machine_learning/ensemble_learning.html">Ensemble learning: bagging, boosting and stacking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimization/optim_gradient_descent.html">Gradient descent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/ml_lab_face_recognition.html">Lab: Faces recognition using various learning models</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="dl_backprop_numpy-pytorch-sklearn.html">Backpropagation</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Multilayer Perceptron (MLP)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#course-outline">Course outline:</a></li>
<li class="toctree-l2"><a class="reference internal" href="#dataset-mnist-handwritten-digit-recognition">Dataset: MNIST Handwritten Digit Recognition</a></li>
<li class="toctree-l2"><a class="reference internal" href="#recall-of-linear-classifier">Recall of linear classifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="#model-two-layer-mlp">Model: Two Layer MLP</a></li>
<li class="toctree-l2"><a class="reference internal" href="#test-several-mlp-architectures">Test several MLP architectures</a></li>
<li class="toctree-l2"><a class="reference internal" href="#reduce-the-size-of-training-dataset">Reduce the size of training dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="#run-mlp-on-cifar-10-dataset">Run MLP on CIFAR-10 dataset</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="dl_cnn_cifar10_pytorch.html">Convolutional neural network</a></li>
<li class="toctree-l1"><a class="reference internal" href="dl_transfer-learning_cifar10-ants-bees_pytorch.html">Transfer Learning Tutorial</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="dl_backprop_numpy-pytorch-sklearn.html" title="previous chapter">Backpropagation</a></li>
      <li>Next: <a href="dl_cnn_cifar10_pytorch.html" title="next chapter">Convolutional neural network</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, Edouard Duchesnay, NeuroSpin CEA Université Paris-Saclay, France.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.0.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/deep_learning/dl_mlp_mnist_pytorch.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>