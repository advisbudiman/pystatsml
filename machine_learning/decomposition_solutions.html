
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Dimension reduction and feature extraction &#8212; Statistics and Machine Learning in Python 0.5 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="search" type="application/opensearchdescription+xml"
          title="Search within Statistics and Machine Learning in Python 0.5 documentation"
          href="../_static/opensearch.xml"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="dimension-reduction-and-feature-extraction">
<h1>Dimension reduction and feature extraction<a class="headerlink" href="#dimension-reduction-and-feature-extraction" title="Permalink to this headline">¶</a></h1>
<section id="principal-component-analysis">
<h2>Principal Component Analysis<a class="headerlink" href="#principal-component-analysis" title="Permalink to this headline">¶</a></h2>
<section id="implement-pca">
<h3>Implement PCA<a class="headerlink" href="#implement-pca" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Write a class <code class="docutils literal notranslate"><span class="pre">BasicPCA</span></code> with two methods <code class="docutils literal notranslate"><span class="pre">fit(X)</span></code> that estimates
the data mean and principal components directions. <code class="docutils literal notranslate"><span class="pre">transform(X)</span></code>
that project a new the data into the principal components.</p></li>
<li><p>Check that your <code class="docutils literal notranslate"><span class="pre">BasicPCA</span></code> performed similarly to the one from
sklearn: <code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">sklearn.decomposition</span> <span class="pre">import</span> <span class="pre">PCA</span></code></p></li>
</ul>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="c1">#%matplotlib qt</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>


<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>


<span class="k">class</span> <span class="nc">BasicPCA</span><span class="p">():</span>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="c1"># U : Unitary matrix having left singular vectors as columns.</span>
        <span class="c1">#     Of shape (n_samples,n_samples) or (n_samples,n_comps), depending on</span>
        <span class="c1">#     full_matrices.</span>
        <span class="c1">#</span>
        <span class="c1"># s : The singular values, sorted in non-increasing order. Of shape (n_comps,),</span>
        <span class="c1">#     with n_comps = min(n_samples, n_features).</span>
        <span class="c1">#</span>
        <span class="c1"># Vh: Unitary matrix having right singular vectors as rows.</span>
        <span class="c1">#     Of shape (n_features, n_features) or (n_comps, n_features) depending on full_matrices.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">Xc</span> <span class="o">=</span> <span class="n">X</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span>  <span class="c1"># Centering is required</span>
        <span class="n">U</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">Xc</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">explained_variance_</span> <span class="o">=</span> <span class="p">(</span><span class="n">s</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">explained_variance_ratio_</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">explained_variance_</span> <span class="o">/</span>
                                 <span class="bp">self</span><span class="o">.</span><span class="n">explained_variance_</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">princ_comp_dir</span> <span class="o">=</span> <span class="n">V</span>

    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">Xc</span> <span class="o">=</span> <span class="n">X</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span>
        <span class="k">return</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Xc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">princ_comp_dir</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>

<span class="c1"># test</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># dataset</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">experience</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n_samples</span><span class="p">)</span>
<span class="n">salary</span> <span class="o">=</span> <span class="mi">1500</span> <span class="o">+</span> <span class="n">experience</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">.5</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span><span class="n">experience</span><span class="p">,</span> <span class="n">salary</span><span class="p">])</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span><span class="n">experience</span><span class="p">,</span> <span class="n">salary</span><span class="p">])</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">basic_pca</span> <span class="o">=</span> <span class="n">BasicPCA</span><span class="p">()</span>
<span class="n">basic_pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">basic_pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">==</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="mf">0.93646607</span> <span class="mf">0.06353393</span><span class="p">]</span>
</pre></div>
</div>
</section>
<section id="apply-pca-on-iris-dataset">
<h3>Apply PCA on iris dataset<a class="headerlink" href="#apply-pca-on-iris-dataset" title="Permalink to this headline">¶</a></h3>
<p>Apply your sklearn PCA on <code class="docutils literal notranslate"><span class="pre">iris</span></code> dataset available at:
‘<a class="reference external" href="https://github.com/duchesnay/pystatsml/raw/master/datasets/iris.csv">https://github.com/duchesnay/pystatsml/raw/master/datasets/iris.csv</a>’.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="c1"># https://tgmstat.wordpress.com/2013/11/28/computing-and-visualizing-pca-in-r/</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="k">try</span><span class="p">:</span>
    <span class="n">salary</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;datasets/iris.csv&#39;</span><span class="p">)</span>
<span class="k">except</span><span class="p">:</span>
    <span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://github.com/duchesnay/pystatsml/raw/master/datasets/iris.csv&#39;</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>   <span class="n">sepal_length</span>  <span class="n">sepal_width</span>  <span class="n">petal_length</span>  <span class="n">petal_width</span> <span class="n">species</span>
<span class="mi">0</span>           <span class="mf">5.1</span>          <span class="mf">3.5</span>           <span class="mf">1.4</span>          <span class="mf">0.2</span>  <span class="n">setosa</span>
<span class="mi">1</span>           <span class="mf">4.9</span>          <span class="mf">3.0</span>           <span class="mf">1.4</span>          <span class="mf">0.2</span>  <span class="n">setosa</span>
<span class="mi">2</span>           <span class="mf">4.7</span>          <span class="mf">3.2</span>           <span class="mf">1.3</span>          <span class="mf">0.2</span>  <span class="n">setosa</span>
<span class="mi">3</span>           <span class="mf">4.6</span>          <span class="mf">3.1</span>           <span class="mf">1.5</span>          <span class="mf">0.2</span>  <span class="n">setosa</span>
<span class="mi">4</span>           <span class="mf">5.0</span>          <span class="mf">3.6</span>           <span class="mf">1.4</span>          <span class="mf">0.2</span>  <span class="n">setosa</span>
</pre></div>
</div>
<p>Describe the data set. Should the dataset been standardized ?</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>       <span class="n">sepal_length</span>  <span class="n">sepal_width</span>  <span class="n">petal_length</span>  <span class="n">petal_width</span>
<span class="n">count</span>    <span class="mf">150.000000</span>   <span class="mf">150.000000</span>    <span class="mf">150.000000</span>   <span class="mf">150.000000</span>
<span class="n">mean</span>       <span class="mf">5.843333</span>     <span class="mf">3.057333</span>      <span class="mf">3.758000</span>     <span class="mf">1.199333</span>
<span class="n">std</span>        <span class="mf">0.828066</span>     <span class="mf">0.435866</span>      <span class="mf">1.765298</span>     <span class="mf">0.762238</span>
<span class="nb">min</span>        <span class="mf">4.300000</span>     <span class="mf">2.000000</span>      <span class="mf">1.000000</span>     <span class="mf">0.100000</span>
<span class="mi">25</span><span class="o">%</span>        <span class="mf">5.100000</span>     <span class="mf">2.800000</span>      <span class="mf">1.600000</span>     <span class="mf">0.300000</span>
<span class="mi">50</span><span class="o">%</span>        <span class="mf">5.800000</span>     <span class="mf">3.000000</span>      <span class="mf">4.350000</span>     <span class="mf">1.300000</span>
<span class="mi">75</span><span class="o">%</span>        <span class="mf">6.400000</span>     <span class="mf">3.300000</span>      <span class="mf">5.100000</span>     <span class="mf">1.800000</span>
<span class="nb">max</span>        <span class="mf">7.900000</span>     <span class="mf">4.400000</span>      <span class="mf">6.900000</span>     <span class="mf">2.500000</span>
</pre></div>
</div>
<p>Describe the structure of correlation among variables.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">4</span><span class="p">])</span>
<span class="c1">#np.around(np.corrcoef(X.T), 3)</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Center and standardize</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">4</span><span class="p">])</span>
<span class="n">X</span> <span class="o">-=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">around</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">),</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([[</span> <span class="mf">1.</span>   <span class="p">,</span> <span class="o">-</span><span class="mf">0.118</span><span class="p">,</span>  <span class="mf">0.872</span><span class="p">,</span>  <span class="mf">0.818</span><span class="p">],</span>
       <span class="p">[</span><span class="o">-</span><span class="mf">0.118</span><span class="p">,</span>  <span class="mf">1.</span>   <span class="p">,</span> <span class="o">-</span><span class="mf">0.428</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.366</span><span class="p">],</span>
       <span class="p">[</span> <span class="mf">0.872</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.428</span><span class="p">,</span>  <span class="mf">1.</span>   <span class="p">,</span>  <span class="mf">0.963</span><span class="p">],</span>
       <span class="p">[</span> <span class="mf">0.818</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.366</span><span class="p">,</span>  <span class="mf">0.963</span><span class="p">,</span>  <span class="mf">1.</span>   <span class="p">]])</span>
</pre></div>
</div>
<p>Compute a PCA with the maximum number of components.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
<p>Retrieve the explained variance ratio. Determine <span class="math notranslate nohighlight">\(K\)</span> the number of
components.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">)</span>

<span class="n">K</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">PC</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="c1">#print(PC)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="mf">0.72962445</span> <span class="mf">0.22850762</span> <span class="mf">0.03668922</span> <span class="mf">0.00517871</span><span class="p">]</span>
</pre></div>
</div>
<p>Print the <span class="math notranslate nohighlight">\(K\)</span> principal components direction and correlation of
the <span class="math notranslate nohighlight">\(K\)</span> principal components with original variables. Interpret
the contribution of original variables into the PC.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">components_</span><span class="p">)</span>
<span class="n">CorPC</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">[[</span><span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="n">j</span><span class="p">],</span> <span class="n">PC</span><span class="p">[:,</span> <span class="n">k</span><span class="p">])[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">)],</span>
            <span class="n">columns</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">[:</span><span class="mi">4</span><span class="p">],</span>
    <span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;PC </span><span class="si">%i</span><span class="s2">&quot;</span><span class="o">%</span><span class="k">k</span> for k in range(K)]
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">CorPC</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[[</span> <span class="mf">0.52106591</span> <span class="o">-</span><span class="mf">0.26934744</span>  <span class="mf">0.5804131</span>   <span class="mf">0.56485654</span><span class="p">]</span>
 <span class="p">[</span> <span class="mf">0.37741762</span>  <span class="mf">0.92329566</span>  <span class="mf">0.02449161</span>  <span class="mf">0.06694199</span><span class="p">]</span>
 <span class="p">[</span><span class="o">-</span><span class="mf">0.71956635</span>  <span class="mf">0.24438178</span>  <span class="mf">0.14212637</span>  <span class="mf">0.63427274</span><span class="p">]</span>
 <span class="p">[</span><span class="o">-</span><span class="mf">0.26128628</span>  <span class="mf">0.12350962</span>  <span class="mf">0.80144925</span> <span class="o">-</span><span class="mf">0.52359713</span><span class="p">]]</span>
      <span class="n">sepal_length</span>  <span class="n">sepal_width</span>  <span class="n">petal_length</span>  <span class="n">petal_width</span>
<span class="n">PC</span> <span class="mi">0</span>      <span class="mf">0.890169</span>    <span class="o">-</span><span class="mf">0.460143</span>      <span class="mf">0.991555</span>     <span class="mf">0.964979</span>
<span class="n">PC</span> <span class="mi">1</span>      <span class="mf">0.360830</span>     <span class="mf">0.882716</span>      <span class="mf">0.023415</span>     <span class="mf">0.064000</span>
</pre></div>
</div>
<p>Plot samples projected into the <span class="math notranslate nohighlight">\(K\)</span> first PCs. Color samples with
their species.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">colors</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;setosa&#39;</span><span class="p">:</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="s1">&#39;versicolor&#39;</span><span class="p">:</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="s1">&#39;virginica&#39;</span><span class="p">:</span><span class="s1">&#39;blue&#39;</span><span class="p">}</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;species&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
<span class="c1">#plt.scatter(df[&#39;experience&#39;], df[&#39;salary&#39;], c=df[&#39;education&#39;].apply(lambda x: colors[x]), s=100)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">PC</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">PC</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;species&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">colors</span><span class="p">[</span><span class="n">x</span><span class="p">]))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;PC1&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;PC2&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="s1">&#39;setosa&#39;</span> <span class="s1">&#39;versicolor&#39;</span> <span class="s1">&#39;virginica&#39;</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Text</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s1">&#39;PC2&#39;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../_images/decomposition_solutions_16_2.png" src="../_images/decomposition_solutions_16_2.png" />
<p>Pairewise plot</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">df</span><span class="p">[</span><span class="s2">&quot;PC1&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">PC</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;PC2&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">PC</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;species&quot;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../_images/decomposition_solutions_18_0.png" src="../_images/decomposition_solutions_18_0.png" />
</section>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">Statistics and Machine Learning in Python</a></h1>








<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../introduction/python_ecosystem.html">Python ecosystem for data-science</a></li>
<li class="toctree-l1"><a class="reference internal" href="../introduction/machine_learning.html">Introduction to Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../introduction/machine_learning.html#data-analysis-methodology">Data analysis methodology</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html">Import libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#basic-operations">Basic operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#data-types">Data types</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#execution-control-statements">Execution control statements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#list-comprehensions-iterators-etc">List comprehensions, iterators, etc.</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#functions">Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#regular-expression">Regular expression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#system-programming">System programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#scripts-and-argument-parsing">Scripts and argument parsing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#networking">Networking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#modules-and-packages">Modules and packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#object-oriented-programming-oop">Object Oriented Programming (OOP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#style-guide-for-python-programming">Style guide for Python programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#documenting">Documenting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#exercises">Exercises</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/scipy_numpy.html">Numpy: arrays and matrices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/scipy_pandas.html">Pandas: data manipulation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scientific_python/scipy_matplotlib.html">Data visualization: matplotlib &amp; seaborn</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../statistics/stat_univ.html">Univariate statistics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/stat_univ_lab_brain-volume.html">Lab: Brain volumes study</a></li>
<li class="toctree-l1"><a class="reference internal" href="../statistics/stat_multiv.html">Multivariate statistics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../statistics/time_series.html">Time series in python</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="decomposition.html">Linear dimension reduction and feature extraction</a></li>
<li class="toctree-l1"><a class="reference internal" href="manifold.html">Manifold learning: non-linear dimension reduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="clustering.html">Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="linear_regression.html">Linear models for regression problems</a></li>
<li class="toctree-l1"><a class="reference internal" href="linear_classification.html">Linear models for classification problems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/ml_supervized_nonlinear.html">Non-linear models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/ml_resampling.html">Resampling methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="ensemble_learning.html">Ensemble learning: bagging, boosting and stacking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimization/optim_gradient_descent.html">Gradient descent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/ml_lab_face_recognition.html">Lab: Faces recognition using various learning models</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../deep_learning/dl_backprop_numpy-pytorch-sklearn.html">Backpropagation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deep_learning/dl_mlp_mnist_pytorch.html">Multilayer Perceptron (MLP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deep_learning/dl_cnn_cifar10_pytorch.html">Convolutional neural network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deep_learning/dl_transfer-learning_cifar10-ants-bees_pytorch.html">Transfer Learning Tutorial</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, Edouard Duchesnay, NeuroSpin CEA Université Paris-Saclay, France.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.0.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/machine_learning/decomposition_solutions.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>