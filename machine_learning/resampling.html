
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Resampling methods &#8212; Statistics and Machine Learning in Python 0.5 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="search" type="application/opensearchdescription+xml"
          title="Search within Statistics and Machine Learning in Python 0.5 documentation"
          href="../_static/opensearch.xml"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="resampling-methods">
<h1>Resampling methods<a class="headerlink" href="#resampling-methods" title="Permalink to this headline">¶</a></h1>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
<section id="train-validation-and-test-sets">
<h2>Train, Validation and Test Sets<a class="headerlink" href="#train-validation-and-test-sets" title="Permalink to this headline">¶</a></h2>
<p>Machine learning algorithms overfit taining data. Predictive
performances <strong>MUST</strong> be evaluated on independant hold-out dataset.</p>
<figure class="align-default" id="id1">
<img alt="Train, validation and test sets." src="../_images/train_val_test_cv1.png" />
<figcaption>
<p><span class="caption-text">Train, validation and test sets.</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<ol class="arabic simple">
<li><p><strong>Training dataset</strong>: Dataset used to fit the model (set the model
parameters like weights). The <em>training error</em> can be easily
calculated by applying the statistical learning method to the
observations used in its training. But because of overfitting, the
<strong>training error rate can dramatically underestimate the error</strong> that
would be obtained on new samples.</p></li>
<li><p><strong>Validation dataset</strong>: Dataset used to provide an unbiased
evaluation of a model fit on the training dataset while <strong>tuning
model hyperparameters</strong>, ie. <strong>Model selection</strong>. The validation
error is the average error that results from a learning method to
predict the response on a new (validation) samples that is, on
samples that were not used in training the method.</p></li>
<li><p><strong>Test dataset</strong>: Dataset used to provide an unbiased <strong>evaluation of
a final model</strong> fitted on the training dataset. It is only used once
a model is completely trained(using the train and validation sets).</p></li>
</ol>
<p>What is the Difference Between Test and Validation Datasets? by <a class="reference external" href="https://machinelearningmastery.com/difference-test-validation-datasets/">Jason
Brownlee</a></p>
<p>Thus the original dataset is generally split in a training, validation
and a test data sets. Large training+validation set (80%) small test set
(20%) might provide a poor estimation of the predictive performances
(same argument stands for train vs validation samples). On the contrary,
large test set and small training set might produce a poorly estimated
learner. This is why, on situation where we cannot afford such split,
cross-validation scheme can be use for model selection or/and for model
evaluation.</p>
<p>If sample size is limited, train/validation/test split may not be
possible. <strong>Cross Validation (CV)</strong> (see below) can be used to replace:</p>
<ul class="simple">
<li><p>Outer (train/test) split of model evaluation.</p></li>
<li><p>Inner train/validation split of model selection (more frequent
situation).</p></li>
<li><p>Inner and outer splits, leading to two nested CV.</p></li>
</ul>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">import</span> <span class="nn">sklearn.linear_model</span> <span class="k">as</span> <span class="nn">lm</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">PredefinedSplit</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">GridSearchCV</span>

<span class="kn">import</span> <span class="nn">sklearn.metrics</span> <span class="k">as</span> <span class="nn">metrics</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                         <span class="n">n_informative</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
<section id="split-dataset-in-train-test-sets-for-model-outer-evaluation">
<h3>1. Split dataset in train/test sets for model (outer) evaluation<a class="headerlink" href="#split-dataset-in-train-test-sets-for-model-outer-evaluation" title="Permalink to this headline">¶</a></h3>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="predefined-train-validation-split-for-model-inner-selection">
<h3>1.1 Predefined train/validation split for model (inner) selection<a class="headerlink" href="#predefined-train-validation-split-for-model-inner-selection" title="Permalink to this headline">¶</a></h3>
<p>Re-split train set into train/validation and build a CV object (inner
split) out of it:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_idx</span><span class="p">,</span> <span class="n">validation_idx</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
                                             <span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">split_inner</span> <span class="o">=</span> <span class="n">PredefinedSplit</span><span class="p">(</span><span class="n">test_fold</span><span class="o">=</span><span class="n">validation_idx</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train set size: </span><span class="si">%i</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">X_train</span><span class="p">[</span><span class="n">train_idx</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Validation set size: </span><span class="si">%i</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">X_train</span><span class="p">[</span><span class="n">validation_idx</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set size: </span><span class="si">%i</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">lm_cv</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">lm</span><span class="o">.</span><span class="n">Ridge</span><span class="p">(),</span> <span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="mf">10.</span> <span class="o">**</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)},</span>
                     <span class="n">cv</span><span class="o">=</span><span class="n">split_inner</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># Fit, indluding model selection with internal Train/validation split</span>
<span class="n">lm_cv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Predict</span>
<span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">lm_cv</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test R2: </span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">metrics</span><span class="o">.</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_test</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Train</span> <span class="nb">set</span> <span class="n">size</span><span class="p">:</span> <span class="mi">56</span>
<span class="n">Validation</span> <span class="nb">set</span> <span class="n">size</span><span class="p">:</span> <span class="mi">19</span>
<span class="n">Test</span> <span class="nb">set</span> <span class="n">size</span><span class="p">:</span> <span class="mi">25</span>
<span class="n">Test</span> <span class="n">R2</span><span class="p">:</span> <span class="mf">0.80</span>
</pre></div>
</div>
</section>
<section id="cross-validation-for-model-inner-selection">
<h3>1.2 Cross-validation for model (inner) selection<a class="headerlink" href="#cross-validation-for-model-inner-selection" title="Permalink to this headline">¶</a></h3>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cv_inner</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train/Validation set sizes: &quot;</span><span class="p">,</span>
      <span class="p">[[</span><span class="nb">len</span><span class="p">(</span><span class="n">tr</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">ev</span><span class="p">)]</span> <span class="k">for</span> <span class="n">tr</span><span class="p">,</span> <span class="n">ev</span> <span class="ow">in</span> <span class="n">cv_inner</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X_train</span><span class="p">)])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set size: </span><span class="si">%i</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="c1"># Cross-validation for model selection</span>
<span class="n">lm_cv</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">lm</span><span class="o">.</span><span class="n">Ridge</span><span class="p">(),</span> <span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="mf">10.</span> <span class="o">**</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)},</span>
                     <span class="n">cv</span><span class="o">=</span><span class="n">cv_inner</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># Fit, indluding model selection with internal CV</span>
<span class="n">lm_cv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Predict</span>
<span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">lm_cv</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test R2: </span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">metrics</span><span class="o">.</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_test</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Train</span><span class="o">/</span><span class="n">Validation</span> <span class="nb">set</span> <span class="n">sizes</span><span class="p">:</span>  <span class="p">[[</span><span class="mi">60</span><span class="p">,</span> <span class="mi">15</span><span class="p">],</span> <span class="p">[</span><span class="mi">60</span><span class="p">,</span> <span class="mi">15</span><span class="p">],</span> <span class="p">[</span><span class="mi">60</span><span class="p">,</span> <span class="mi">15</span><span class="p">],</span> <span class="p">[</span><span class="mi">60</span><span class="p">,</span> <span class="mi">15</span><span class="p">],</span> <span class="p">[</span><span class="mi">60</span><span class="p">,</span> <span class="mi">15</span><span class="p">]]</span>
<span class="n">Test</span> <span class="nb">set</span> <span class="n">size</span><span class="p">:</span> <span class="mi">25</span>
<span class="n">Test</span> <span class="n">R2</span><span class="p">:</span> <span class="mf">0.80</span>
</pre></div>
</div>
</section>
<section id="cross-validation-for-both-model-outer-evaluation-and-model-inner-selection">
<h3>2. Cross-validation for both model (outer) evaluation and model (inner) selection<a class="headerlink" href="#cross-validation-for-both-model-outer-evaluation-and-model-inner-selection" title="Permalink to this headline">¶</a></h3>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cv_outer</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">sizes</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([[</span><span class="nb">len</span><span class="p">(</span><span class="n">train</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">eva</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">test</span><span class="p">)]</span>
       <span class="k">for</span> <span class="n">tr_outer</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">cv_outer</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
       <span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">eva</span> <span class="ow">in</span> <span class="n">cv_inner</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">tr_outer</span><span class="p">])</span>
      <span class="p">],</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="s1">&#39;validation&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train/Validation set sizes: &quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sizes</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">4</span><span class="p">:</span><span class="mi">0</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Nb runs: </span><span class="si">%i</span><span class="s2"> (nb outer folds x nb inner folds)&quot;</span> <span class="o">%</span> <span class="n">sizes</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="c1"># Cross-validation for model (inner) selection</span>
<span class="n">lm_cv</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">lm</span><span class="o">.</span><span class="n">Ridge</span><span class="p">(),</span> <span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="mf">10.</span> <span class="o">**</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)},</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv_inner</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># Cross-validation for model (outer) evaluation</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">lm_cv</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv_outer</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;CV R2:</span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Train</span><span class="o">/</span><span class="n">Validation</span> <span class="nb">set</span> <span class="n">sizes</span><span class="p">:</span>
    <span class="n">train</span>  <span class="n">validation</span>  <span class="n">test</span>
<span class="mi">0</span>      <span class="mi">64</span>          <span class="mi">16</span>    <span class="mi">20</span>
<span class="mi">1</span>      <span class="mi">64</span>          <span class="mi">16</span>    <span class="mi">20</span>
<span class="mi">2</span>      <span class="mi">64</span>          <span class="mi">16</span>    <span class="mi">20</span>
<span class="mi">3</span>      <span class="mi">64</span>          <span class="mi">16</span>    <span class="mi">20</span>
<span class="mi">21</span>     <span class="mi">64</span>          <span class="mi">16</span>    <span class="mi">20</span>
<span class="mi">22</span>     <span class="mi">64</span>          <span class="mi">16</span>    <span class="mi">20</span>
<span class="mi">23</span>     <span class="mi">64</span>          <span class="mi">16</span>    <span class="mi">20</span>
<span class="mi">24</span>     <span class="mi">64</span>          <span class="mi">16</span>    <span class="mi">20</span>
<span class="n">Nb</span> <span class="n">runs</span><span class="p">:</span> <span class="mi">25</span> <span class="p">(</span><span class="n">nb</span> <span class="n">outer</span> <span class="n">folds</span> <span class="n">x</span> <span class="n">nb</span> <span class="n">inner</span> <span class="n">folds</span><span class="p">)</span>
<span class="n">CV</span> <span class="n">R2</span><span class="p">:</span><span class="mf">0.70</span>
</pre></div>
</div>
</section>
</section>
<section id="cross-validation-cv">
<h2>Cross-Validation (CV)<a class="headerlink" href="#cross-validation-cv" title="Permalink to this headline">¶</a></h2>
<p>Cross-Validation scheme randomly divides the set of observations into
<span class="math notranslate nohighlight">\(K\)</span> groups, or <strong>folds</strong>, of approximately equal size. The first
fold is treated as a validation set, and the method <span class="math notranslate nohighlight">\(f()\)</span> is
fitted on the remaining union of <span class="math notranslate nohighlight">\(K - 1\)</span> folds:
(<span class="math notranslate nohighlight">\(f(\boldsymbol{X}_{-K}, \boldsymbol{y}_{-K})\)</span>).</p>
<p>The measure of performance (the score function <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>),
either a error measure or an correct prediction measure is an average of
a loss error or correct prediction measure, noted <span class="math notranslate nohighlight">\(\mathcal{L}\)</span>,
between a true target value and the predicted target value. The score
function is evaluated of the on the observations in the held-out fold.
For each sample <span class="math notranslate nohighlight">\(i\)</span> we consider the model estimated
<span class="math notranslate nohighlight">\(f(\boldsymbol{X}_{-k(i)}, \boldsymbol{y}_{-k(i)}\)</span> on the data set
without the group <span class="math notranslate nohighlight">\(k\)</span> that contains <span class="math notranslate nohighlight">\(i\)</span> noted <span class="math notranslate nohighlight">\(-k(i)\)</span>.
This procedure is repeated <span class="math notranslate nohighlight">\(K\)</span> times; each time, a different group
of observations is treated as a test set. Then we compare the predicted
value (<span class="math notranslate nohighlight">\(f_{-k(i)}(\boldsymbol{x}_i) = \hat{y_i})\)</span> with true value
<span class="math notranslate nohighlight">\(y_i\)</span> using a Error or Loss function
<span class="math notranslate nohighlight">\(\mathcal{L}(y, \hat{y})\)</span>.</p>
<p>For 10-fold we can either average over 10 values (Macro measure) or
concatenate the 10 experiments and compute the micro measures.</p>
<p>Two strategies <a class="reference external" href="https://stats.stackexchange.com/questions/34611/meanscores-vs-scoreconcatenation-in-cross-validation">micro vs macro
estimates</a>:</p>
<p><strong>Micro measure: average(individual scores)</strong>: compute a score
<span class="math notranslate nohighlight">\(\mathcal{S}\)</span> for each sample and average over all samples. It is
simillar to <strong>average score(concatenation)</strong>: an averaged score computed
over all concatenated samples.</p>
<div class="math notranslate nohighlight">
\[\mathcal{S}(f) = \frac{1}{N} \sum_i^N \mathcal{L}\left(y_i, f(\boldsymbol{x}_{-k(i)}, \boldsymbol{y}_{-k(i)}) \right).\]</div>
<p><strong>Macro measure mean(CV scores)</strong> (the most commonly used method):
compute a score <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> on each each fold <span class="math notranslate nohighlight">\(k\)</span> and
average accross folds:</p>
<p>These two measures (an average of average vs. a global average) are
generaly similar. They may differ slightly is folds are of different
sizes.</p>
<p>This validation scheme is known as the <strong>K-Fold CV</strong>. Typical choices of
<span class="math notranslate nohighlight">\(K\)</span> are 5 or 10, [Kohavi 1995]. The extreme case where
<span class="math notranslate nohighlight">\(K = N\)</span> is known as <strong>leave-one-out cross-validation, LOO-CV</strong>.</p>
<p>Usually the error function <span class="math notranslate nohighlight">\(\mathcal{L}()\)</span> is the r-squared score.
However other function could be used.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">sklearn.metrics</span> <span class="k">as</span> <span class="nn">metrics</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>

<span class="n">estimator</span> <span class="o">=</span> <span class="n">lm</span><span class="o">.</span><span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="n">cv</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">r2_train</span><span class="p">,</span> <span class="n">r2_test</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(),</span> <span class="nb">list</span><span class="p">()</span>

<span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">train</span><span class="p">,</span> <span class="p">:],</span> <span class="n">y</span><span class="p">[</span><span class="n">train</span><span class="p">])</span>
    <span class="n">r2_train</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">estimator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">train</span><span class="p">,</span> <span class="p">:])))</span>
    <span class="n">r2_test</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">test</span><span class="p">],</span> <span class="n">estimator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">test</span><span class="p">,</span> <span class="p">:])))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train r2:</span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">r2_train</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test  r2:</span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">r2_test</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Train</span> <span class="n">r2</span><span class="p">:</span><span class="mf">0.99</span>
<span class="n">Test</span>  <span class="n">r2</span><span class="p">:</span><span class="mf">0.73</span>
</pre></div>
</div>
<p>Scikit-learn provides user-friendly function to perform CV:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test  r2:</span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

<span class="c1"># provide a cv</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test  r2:</span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Test</span>  <span class="n">r2</span><span class="p">:</span><span class="mf">0.73</span>
<span class="n">Test</span>  <span class="n">r2</span><span class="p">:</span><span class="mf">0.73</span>
</pre></div>
</div>
<p>With classification problems it is essential to sample folds where each
set contains approximately the same percentage of samples of each target
class as the complete set. This is called <strong>stratification</strong>. In this
case, we will use <code class="docutils literal notranslate"><span class="pre">StratifiedKFold</span></code> with is a variation of k-fold
which returns stratified folds.</p>
<p>Usually the error function <span class="math notranslate nohighlight">\(L()\)</span> are, at least, the sensitivity
and the specificity. However other function could be used.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">import</span> <span class="nn">sklearn.linear_model</span> <span class="k">as</span> <span class="nn">lm</span>
<span class="kn">import</span> <span class="nn">sklearn.metrics</span> <span class="k">as</span> <span class="nn">metrics</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedKFold</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                         <span class="n">n_informative</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">estimator</span> <span class="o">=</span> <span class="n">lm</span><span class="o">.</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">)</span>

<span class="n">cv</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># Lists to store scores by folds (for macro measure only)</span>
<span class="n">recalls_train</span><span class="p">,</span> <span class="n">recalls_test</span><span class="p">,</span> <span class="n">acc_test</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(),</span> <span class="nb">list</span><span class="p">(),</span> <span class="nb">list</span><span class="p">()</span>

<span class="c1"># Or vector of test predictions (for both macro and micro measures, not for training samples)</span>
<span class="n">y_test_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>

<span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">train</span><span class="p">,</span> <span class="p">:],</span> <span class="n">y</span><span class="p">[</span><span class="n">train</span><span class="p">])</span>
    <span class="n">recalls_train</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">estimator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">train</span><span class="p">,</span> <span class="p">:]),</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">))</span>
    <span class="n">recalls_test</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">test</span><span class="p">],</span> <span class="n">estimator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">test</span><span class="p">,</span> <span class="p">:]),</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">))</span>
    <span class="n">acc_test</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">test</span><span class="p">],</span> <span class="n">estimator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">test</span><span class="p">,</span> <span class="p">:])))</span>

    <span class="c1"># Store test predictions (for micro measures)</span>
    <span class="n">y_test_pred</span><span class="p">[</span><span class="n">test</span><span class="p">]</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">test</span><span class="p">,</span> <span class="p">:])</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;== Macro measures ==&quot;</span><span class="p">)</span>
<span class="c1"># Use lists of scores</span>
<span class="n">recalls_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">recalls_train</span><span class="p">)</span>
<span class="n">recalls_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">recalls_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train SPC:</span><span class="si">%.2f</span><span class="s2">; SEN:</span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">recalls_train</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test  SPC:</span><span class="si">%.2f</span><span class="s2">; SEN:</span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">recalls_test</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)),</span> <span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test  ACC:</span><span class="si">%.2f</span><span class="s2">, ballanced ACC:</span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span>
      <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">acc_test</span><span class="p">),</span> <span class="n">recalls_test</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()),</span> <span class="s2">&quot;Folds:&quot;</span><span class="p">,</span> <span class="n">acc_test</span><span class="p">)</span>

<span class="c1"># Or use vector to test predictions</span>
<span class="n">acc_test</span> <span class="o">=</span> <span class="p">[</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">test</span><span class="p">],</span> <span class="n">y_test_pred</span><span class="p">[</span><span class="n">test</span><span class="p">])</span> <span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test  ACC:</span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">acc_test</span><span class="p">),</span> <span class="s2">&quot;Folds:&quot;</span><span class="p">,</span> <span class="n">acc_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;== Micro measures ==&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test SPC:</span><span class="si">%.2f</span><span class="s2">; SEN:</span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> \
      <span class="nb">tuple</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_test_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test  ACC:</span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_test_pred</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">==</span> <span class="n">Macro</span> <span class="n">measures</span> <span class="o">==</span>
<span class="n">Train</span> <span class="n">SPC</span><span class="p">:</span><span class="mf">1.00</span><span class="p">;</span> <span class="n">SEN</span><span class="p">:</span><span class="mf">1.00</span>
<span class="n">Test</span>  <span class="n">SPC</span><span class="p">:</span><span class="mf">0.78</span><span class="p">;</span> <span class="n">SEN</span><span class="p">:</span><span class="mf">0.82</span>
<span class="n">Test</span>  <span class="n">ACC</span><span class="p">:</span><span class="mf">0.80</span><span class="p">,</span> <span class="n">ballanced</span> <span class="n">ACC</span><span class="p">:</span><span class="mf">0.80</span> <span class="n">Folds</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">]</span>
<span class="n">Test</span>  <span class="n">ACC</span><span class="p">:</span><span class="mf">0.80</span> <span class="n">Folds</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">]</span>
<span class="o">==</span> <span class="n">Micro</span> <span class="n">measures</span> <span class="o">==</span>
<span class="n">Test</span> <span class="n">SPC</span><span class="p">:</span><span class="mf">0.78</span><span class="p">;</span> <span class="n">SEN</span><span class="p">:</span><span class="mf">0.82</span>
<span class="n">Test</span>  <span class="n">ACC</span><span class="p">:</span><span class="mf">0.80</span>
</pre></div>
</div>
<p>Scikit-learn provides user-friendly function to perform CV:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="c1"># provide CV and score</span>
<span class="k">def</span> <span class="nf">balanced_acc</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Balanced acuracy scorer</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">return</span> <span class="n">metrics</span><span class="o">.</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">estimator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">balanced_acc</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test  ACC:</span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Test</span>  <span class="n">ACC</span><span class="p">:</span><span class="mf">0.80</span>
</pre></div>
</div>
<p>Note that with Scikit-learn user-friendly function we average the
scores’ average obtained on individual folds which may provide slightly
different results that the overall average presented earlier.</p>
</section>
<section id="parallel-computation-with-joblib">
<h2>Parallel computation with joblib<a class="headerlink" href="#parallel-computation-with-joblib" title="Permalink to this headline">¶</a></h2>
<p>Dataset</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">import</span> <span class="nn">sklearn.linear_model</span> <span class="k">as</span> <span class="nn">lm</span>
<span class="kn">import</span> <span class="nn">sklearn.metrics</span> <span class="k">as</span> <span class="nn">metrics</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedKFold</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_informative</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_validate</span>

<span class="n">estimator</span> <span class="o">=</span> <span class="n">lm</span><span class="o">.</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">)</span>
<span class="n">cv_results</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_results</span><span class="p">[</span><span class="s1">&#39;test_score&#39;</span><span class="p">]),</span> <span class="n">cv_results</span><span class="p">[</span><span class="s1">&#39;test_score&#39;</span><span class="p">])</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mf">0.8</span> <span class="p">[</span><span class="mf">0.5</span> <span class="mf">0.5</span> <span class="mf">1.</span>  <span class="mf">1.</span>  <span class="mf">1.</span> <span class="p">]</span>
</pre></div>
</div>
<p>### Sequential computation</p>
<p>If we want have full control of the operations performed within each
fold (retrieve the models parameters, etc.). We would like to
parallelize the folowing sequetial code:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">estimator</span> <span class="o">=</span> <span class="n">lm</span><span class="o">.</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">)</span>
<span class="n">y_test_pred_seq</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">))</span> <span class="c1"># Store predictions in the original order</span>
<span class="n">coefs_seq</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train</span><span class="p">,</span> <span class="p">:],</span> <span class="n">X</span><span class="p">[</span><span class="n">test</span><span class="p">,</span> <span class="p">:],</span> <span class="n">y</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test</span><span class="p">]</span>
    <span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">y_test_pred_seq</span><span class="p">[</span><span class="n">test</span><span class="p">]</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">coefs_seq</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">estimator</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>

<span class="n">test_accs</span> <span class="o">=</span> <span class="p">[</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">test</span><span class="p">],</span> <span class="n">y_test_pred_seq</span><span class="p">[</span><span class="n">test</span><span class="p">])</span> <span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_accs</span><span class="p">),</span> <span class="n">test_accs</span><span class="p">)</span>
<span class="n">coefs_cv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">coefs_seq</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">coefs_cv</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">coefs_cv</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Std Err of the coef&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">coefs_cv</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">coefs_cv</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mf">0.8</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]</span>
<span class="p">[[[</span><span class="o">-</span><span class="mf">0.87692513</span>  <span class="mf">0.6260013</span>   <span class="mf">1.18714373</span> <span class="o">-</span><span class="mf">0.30685978</span> <span class="o">-</span><span class="mf">0.38037393</span><span class="p">]]</span>

 <span class="p">[[</span><span class="o">-</span><span class="mf">0.7464993</span>   <span class="mf">0.62138165</span>  <span class="mf">1.10144804</span>  <span class="mf">0.19800115</span> <span class="o">-</span><span class="mf">0.40112109</span><span class="p">]]</span>

 <span class="p">[[</span><span class="o">-</span><span class="mf">0.96020317</span>  <span class="mf">0.51135134</span>  <span class="mf">1.1210943</span>   <span class="mf">0.08039112</span> <span class="o">-</span><span class="mf">0.2643663</span> <span class="p">]]</span>

 <span class="p">[[</span><span class="o">-</span><span class="mf">0.85755505</span>  <span class="mf">0.52010552</span>  <span class="mf">1.06637346</span> <span class="o">-</span><span class="mf">0.10994258</span> <span class="o">-</span><span class="mf">0.29152132</span><span class="p">]]</span>

 <span class="p">[[</span><span class="o">-</span><span class="mf">0.89914467</span>  <span class="mf">0.51481483</span>  <span class="mf">1.08675378</span> <span class="o">-</span><span class="mf">0.24767837</span> <span class="o">-</span><span class="mf">0.27899525</span><span class="p">]]]</span>
<span class="p">[[</span><span class="o">-</span><span class="mf">0.86806546</span>  <span class="mf">0.55873093</span>  <span class="mf">1.11256266</span> <span class="o">-</span><span class="mf">0.07721769</span> <span class="o">-</span><span class="mf">0.32327558</span><span class="p">]]</span>
<span class="n">Std</span> <span class="n">Err</span> <span class="n">of</span> <span class="n">the</span> <span class="n">coef</span>
<span class="p">[[</span><span class="mf">0.03125544</span> <span class="mf">0.02376198</span> <span class="mf">0.01850211</span> <span class="mf">0.08566194</span> <span class="mf">0.02510739</span><span class="p">]]</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span> <span class="n">Parallel</span><span class="p">,</span> <span class="n">delayed</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">is_classifier</span><span class="p">,</span> <span class="n">clone</span>

<span class="k">def</span> <span class="nf">_split_fit_predict</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">):</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train</span><span class="p">,</span> <span class="p">:],</span> <span class="n">X</span><span class="p">[</span><span class="n">test</span><span class="p">,</span> <span class="p">:],</span> <span class="n">y</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test</span><span class="p">]</span>
    <span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">estimator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">estimator</span><span class="o">.</span><span class="n">coef_</span><span class="p">]</span>

<span class="n">estimator</span> <span class="o">=</span> <span class="n">lm</span><span class="o">.</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">)</span>

<span class="n">parallel</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">cv_ret</span> <span class="o">=</span> <span class="n">parallel</span><span class="p">(</span>
    <span class="n">delayed</span><span class="p">(</span><span class="n">_split_fit_predict</span><span class="p">)(</span>
        <span class="n">clone</span><span class="p">(</span><span class="n">estimator</span><span class="p">),</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>

<span class="n">y_test_pred_cv</span><span class="p">,</span> <span class="n">coefs_cv</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">cv_ret</span><span class="p">)</span>

<span class="c1"># Retrieve predictions in the original order</span>
<span class="n">y_test_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)):</span>
    <span class="n">y_test_pred</span><span class="p">[</span><span class="n">test</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_test_pred_cv</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

<span class="n">test_accs</span> <span class="o">=</span> <span class="p">[</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">test</span><span class="p">],</span> <span class="n">y_test_pred</span><span class="p">[</span><span class="n">test</span><span class="p">])</span> <span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_accs</span><span class="p">),</span> <span class="n">test_accs</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mf">0.8</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]</span>
</pre></div>
</div>
<p>Test same predictions and same coeficients</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">y_test_pred</span> <span class="o">==</span> <span class="n">y_test_pred_seq</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">coefs_cv</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">coefs_seq</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
</pre></div>
</div>
</section>
<section id="cv-for-model-selection-setting-the-hyper-parameters">
<h2>CV for model selection: setting the hyper parameters<a class="headerlink" href="#cv-for-model-selection-setting-the-hyper-parameters" title="Permalink to this headline">¶</a></h2>
<p>It is important to note CV may be used for two separate goals:</p>
<ol class="arabic simple">
<li><p><strong>Model assessment</strong>: having chosen a final model, estimating its
prediction error (generalization error) on new data.</p></li>
<li><p><strong>Model selection</strong>: estimating the performance of different models
in order to choose the best one. One special case of model selection
is the selection model’s hyper parameters. Indeed remember that most
of learning algorithm have a hyper parameters (typically the
regularization parameter) that has to be set.</p></li>
</ol>
<p>Generally we must address the two problems simultaneously. The usual
approach for both problems is to randomly divide the dataset into three
parts: a training set, a validation set, and a test set.</p>
<ul class="simple">
<li><p>The <strong>training set</strong> (train) is used to fit the models;</p></li>
<li><p>the <strong>validation set</strong> (val) is used to estimate prediction error for
model selection or to determine the hyper parameters over a grid of
possible values.</p></li>
<li><p>the <strong>test set</strong> (test) is used for assessment of the generalization
error of the final chosen model.</p></li>
</ul>
<p>Model selection of the best hyper parameters over a grid of possible
values</p>
<p>For each possible values of hyper parameters <span class="math notranslate nohighlight">\(\alpha_k\)</span>:</p>
<ol class="arabic">
<li><p>Fit the learner on training set:
<span class="math notranslate nohighlight">\(f(X_{train}, y_{train}, \alpha_k)\)</span></p></li>
<li><p>Evaluate the model on the validation set and keep the parameter(s)
that minimises the error measure</p>
<p><span class="math notranslate nohighlight">\(\alpha_* = \arg \min L(f(X_{train}), y_{val}, \alpha_k)\)</span></p>
</li>
<li><p>Refit the learner on all training + validation data using the best
hyper parameters:
<span class="math notranslate nohighlight">\(f^* \equiv f(X_{train \cup val}, y_{train \cup val}, \alpha_*)\)</span></p></li>
<li><p>** Model assessment ** of <span class="math notranslate nohighlight">\(f^*\)</span> on the test set:
<span class="math notranslate nohighlight">\(L(f^*(X_{test}), y_{test})\)</span></p></li>
</ol>
<p>Most of time, we cannot afford such three-way split. Thus, again we will
use CV, but in this case we need two nested CVs.</p>
<p>One <strong>outer CV loop, for model assessment</strong>. This CV performs <span class="math notranslate nohighlight">\(K\)</span>
splits of the dataset into training plus validation
(<span class="math notranslate nohighlight">\(X_{-K}, y_{-K}\)</span>) set and a test set <span class="math notranslate nohighlight">\(X_{K}, y_{K}\)</span></p>
<p>One <strong>inner CV loop, for model selection</strong>. For each run of the outer
loop, the inner loop loop performs <span class="math notranslate nohighlight">\(L\)</span> splits of dataset
(<span class="math notranslate nohighlight">\(X_{-K}, y_{-K}\)</span>) into training set:
(<span class="math notranslate nohighlight">\(X_{-K,-L}, y_{-K,-L}\)</span>) and a validation set:
(<span class="math notranslate nohighlight">\(X_{-K,L}, y_{-K,L}\)</span>).</p>
<p>Note that the inner CV loop combined with the learner form a new learner
with an automatic model (parameter) selection procedure. This new
learner can be easily constructed using Scikit-learn. The learned is
wrapped inside a <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> class.</p>
<p>Then the new learned can be plugged into the classical outer CV loop.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">import</span> <span class="nn">sklearn.linear_model</span> <span class="k">as</span> <span class="nn">lm</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="kn">import</span> <span class="nn">sklearn.metrics</span> <span class="k">as</span> <span class="nn">metrics</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>

<span class="c1"># Dataset</span>
<span class="n">noise_sd</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">coef</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="n">noise_sd</span><span class="p">,</span>
                         <span class="n">n_informative</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">coef</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Use this to tune the noise parameter such that snr &lt; 5</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;SNR:&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">coef</span><span class="p">))</span> <span class="o">/</span> <span class="n">noise_sd</span><span class="p">)</span>

<span class="c1"># param grid over alpha &amp; l1_ratio</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="mf">10.</span> <span class="o">**</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="s1">&#39;l1_ratio&#39;</span><span class="p">:[</span><span class="mf">.1</span><span class="p">,</span> <span class="mf">.5</span><span class="p">,</span> <span class="mf">.9</span><span class="p">]}</span>

<span class="c1"># Warp</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">lm</span><span class="o">.</span><span class="n">ElasticNet</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">),</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">SNR</span><span class="p">:</span> <span class="mf">2.6358469446381614</span>
</pre></div>
</div>
<p>Sklearn will automatically select a grid of parameters, most of time use
the defaults values.</p>
<p><code class="docutils literal notranslate"><span class="pre">n_jobs</span></code> is the number of CPUs to use during the cross validation. If
-1, use all the CPUs.</p>
<ol class="arabic simple">
<li><p>Biased usage: fit on all data, ommit outer CV loop</p></li>
</ol>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train r2:</span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">metrics</span><span class="o">.</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Train</span> <span class="n">r2</span><span class="p">:</span><span class="mf">0.96</span>
<span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span> <span class="s1">&#39;l1_ratio&#39;</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">}</span>
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>User made outer CV, useful to extract specific information</p></li>
</ol>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cv</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">r2_train</span><span class="p">,</span> <span class="n">r2_test</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(),</span> <span class="nb">list</span><span class="p">()</span>
<span class="n">alphas</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>

<span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train</span><span class="p">,</span> <span class="p">:],</span> <span class="n">X</span><span class="p">[</span><span class="n">test</span><span class="p">,</span> <span class="p">:],</span> <span class="n">y</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test</span><span class="p">]</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="n">r2_test</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)))</span>
    <span class="n">r2_train</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)))</span>

    <span class="n">alphas</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train r2:</span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">r2_train</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test  r2:</span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">r2_test</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Selected alphas:&quot;</span><span class="p">,</span> <span class="n">alphas</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Train</span> <span class="n">r2</span><span class="p">:</span><span class="mf">1.00</span>
<span class="n">Test</span>  <span class="n">r2</span><span class="p">:</span><span class="mf">0.55</span>
<span class="n">Selected</span> <span class="n">alphas</span><span class="p">:</span> <span class="p">[{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span> <span class="s1">&#39;l1_ratio&#39;</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">},</span> <span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span> <span class="s1">&#39;l1_ratio&#39;</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">},</span> <span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span> <span class="s1">&#39;l1_ratio&#39;</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">},</span> <span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">,</span> <span class="s1">&#39;l1_ratio&#39;</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">},</span> <span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span> <span class="s1">&#39;l1_ratio&#39;</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">}]</span>
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li><p>User-friendly sklearn for outer CV</p></li>
</ol>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test  r2:</span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Test</span>  <span class="n">r2</span><span class="p">:</span><span class="mf">0.55</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">import</span> <span class="nn">sklearn.linear_model</span> <span class="k">as</span> <span class="nn">lm</span>
<span class="kn">import</span> <span class="nn">sklearn.metrics</span> <span class="k">as</span> <span class="nn">metrics</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="c1"># Dataset</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">coef</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                         <span class="n">n_informative</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">coef</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;== Ridge (L2 penalty) ==&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">lm</span><span class="o">.</span><span class="n">RidgeCV</span><span class="p">(</span><span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="c1"># Let sklearn select a list of alphas with default LOO-CV</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test  r2:</span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;== Lasso (L1 penalty) ==&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">lm</span><span class="o">.</span><span class="n">LassoCV</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="c1"># Let sklearn select a list of alphas with default 3CV</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test  r2:</span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;== ElasticNet (L1 penalty) ==&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">lm</span><span class="o">.</span><span class="n">ElasticNetCV</span><span class="p">(</span><span class="n">l1_ratio</span><span class="o">=</span><span class="p">[</span><span class="mf">.1</span><span class="p">,</span> <span class="mf">.5</span><span class="p">,</span> <span class="mf">.9</span><span class="p">],</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="c1"># Let sklearn select a list of alphas with default 3CV</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test  r2:</span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">==</span> <span class="n">Ridge</span> <span class="p">(</span><span class="n">L2</span> <span class="n">penalty</span><span class="p">)</span> <span class="o">==</span>
<span class="n">Test</span>  <span class="n">r2</span><span class="p">:</span><span class="mf">0.16</span>
<span class="o">==</span> <span class="n">Lasso</span> <span class="p">(</span><span class="n">L1</span> <span class="n">penalty</span><span class="p">)</span> <span class="o">==</span>
<span class="n">Test</span>  <span class="n">r2</span><span class="p">:</span><span class="mf">0.74</span>
<span class="o">==</span> <span class="n">ElasticNet</span> <span class="p">(</span><span class="n">L1</span> <span class="n">penalty</span><span class="p">)</span> <span class="o">==</span>
<span class="n">Test</span>  <span class="n">r2</span><span class="p">:</span><span class="mf">0.58</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">import</span> <span class="nn">sklearn.linear_model</span> <span class="k">as</span> <span class="nn">lm</span>
<span class="kn">import</span> <span class="nn">sklearn.metrics</span> <span class="k">as</span> <span class="nn">metrics</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                         <span class="n">n_informative</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># provide CV and score</span>
<span class="k">def</span> <span class="nf">balanced_acc</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Balanced accuracy scorer</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">return</span> <span class="n">metrics</span><span class="o">.</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">estimator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;== Logistic Ridge (L2 penalty) ==&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">lm</span><span class="o">.</span><span class="n">LogisticRegressionCV</span><span class="p">(</span><span class="n">class_weight</span><span class="o">=</span><span class="s1">&#39;balanced&#39;</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">balanced_acc</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="c1"># Let sklearn select a list of alphas with default LOO-CV</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test  ACC:</span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">==</span> <span class="n">Logistic</span> <span class="n">Ridge</span> <span class="p">(</span><span class="n">L2</span> <span class="n">penalty</span><span class="p">)</span> <span class="o">==</span>
<span class="n">Test</span>  <span class="n">ACC</span><span class="p">:</span><span class="mf">0.76</span>
</pre></div>
</div>
</section>
<section id="random-permutations-sample-the-null-distribution">
<h2>Random Permutations: sample the null distribution<a class="headerlink" href="#random-permutations-sample-the-null-distribution" title="Permalink to this headline">¶</a></h2>
<p>A permutation test is a type of non-parametric randomization test in
which the null distribution of a test statistic is estimated by randomly
permuting the observations.</p>
<p>Permutation tests are highly attractive because they make no assumptions
other than that the observations are independent and identically
distributed under the null hypothesis.</p>
<ol class="arabic simple">
<li><p>Compute a observed statistic <span class="math notranslate nohighlight">\(t_{obs}\)</span> on the data.</p></li>
<li><p>Use randomization to compute the distribution of <span class="math notranslate nohighlight">\(t\)</span> under the
null hypothesis: Perform <span class="math notranslate nohighlight">\(N\)</span> random permutation of the data.
For each sample of permuted data, <span class="math notranslate nohighlight">\(i\)</span> the data compute the
statistic <span class="math notranslate nohighlight">\(t_i\)</span>. This procedure provides the distribution of
<span class="math notranslate nohighlight">\(t\)</span> under the null hypothesis <span class="math notranslate nohighlight">\(H_0\)</span>:
<span class="math notranslate nohighlight">\(P(t \vert H_0)\)</span></p></li>
<li><p>Compute the p-value =
<span class="math notranslate nohighlight">\(P(t&gt;t_{obs} | H_0) \left\vert\{t_i &gt; t_{obs}\}\right\vert\)</span>,
where <span class="math notranslate nohighlight">\(t_i\)</span>’s include <span class="math notranslate nohighlight">\(t_{obs}\)</span>.</p></li>
</ol>
<p>Sample the distributions of r-squared and coefficients of ridge
regression under the null hypothesis. Simulated dataset:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">sklearn.linear_model</span> <span class="k">as</span> <span class="nn">lm</span>
<span class="kn">import</span> <span class="nn">sklearn.metrics</span> <span class="k">as</span> <span class="nn">metrics</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># Regression dataset</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">n_features</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">n_features_info</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>
<span class="n">beta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_features</span><span class="p">)</span>
<span class="n">beta</span><span class="p">[:</span><span class="n">n_features_info</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">Xbeta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
<span class="n">eps</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">Xbeta</span> <span class="o">+</span> <span class="n">eps</span>
</pre></div>
</div>
<p>Random permutations</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fit model on all data (!! risk of overfit)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">lm</span><span class="o">.</span><span class="n">RidgeCV</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Coefficients on all data:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>

<span class="c1"># Random permutation loop</span>
<span class="n">nperm</span> <span class="o">=</span> <span class="mi">1000</span>  <span class="c1"># !! Should be at least 1000 (to assess a p-value at 1%)</span>
<span class="n">scores_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;r2&quot;</span><span class="p">]</span>
<span class="n">scores_perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">nperm</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">scores_names</span><span class="p">)))</span>
<span class="n">coefs_perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">nperm</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>

<span class="n">scores_perm</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="n">coefs_perm</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span>

<span class="n">orig_all</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="k">for</span> <span class="n">perm_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">nperm</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
    <span class="n">scores_perm</span><span class="p">[</span><span class="n">perm_i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">coefs_perm</span><span class="p">[</span><span class="n">perm_i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span>


<span class="c1"># One-tailed empirical p-value</span>
<span class="n">pval_pred_perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">scores_perm</span> <span class="o">&gt;=</span> <span class="n">scores_perm</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">/</span> <span class="n">scores_perm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">pval_coef_perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">coefs_perm</span> <span class="o">&gt;=</span> <span class="n">coefs_perm</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">coefs_perm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;R2 p-value: </span><span class="si">%.3f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">pval_pred_perm</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Coeficients p-values:&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">pval_coef_perm</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Coefficients</span> <span class="n">on</span> <span class="nb">all</span> <span class="n">data</span><span class="p">:</span>
<span class="p">[</span> <span class="mf">1.01872179</span>  <span class="mf">1.05713711</span>  <span class="mf">0.20873888</span> <span class="o">-</span><span class="mf">0.01784094</span> <span class="o">-</span><span class="mf">0.05265821</span><span class="p">]</span>
<span class="n">R2</span> <span class="n">p</span><span class="o">-</span><span class="n">value</span><span class="p">:</span> <span class="mf">0.001</span>
<span class="n">Coeficients</span> <span class="n">p</span><span class="o">-</span><span class="n">values</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span> <span class="mf">0.001</span> <span class="mf">0.098</span> <span class="mf">0.573</span> <span class="mf">0.627</span><span class="p">]</span>
</pre></div>
</div>
<p>Compute p-values corrected for multiple comparisons using max-T
(Westfall and Young, 1993) FWER</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pval_coef_perm_tmax</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">coefs_perm</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">coefs_perm</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span>
                                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">coefs_perm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])])</span> <span class="o">/</span> <span class="n">coefs_perm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;P-values with FWER (Westfall and Young) correction&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pval_coef_perm_tmax</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">P</span><span class="o">-</span><span class="n">values</span> <span class="k">with</span> <span class="n">FWER</span> <span class="p">(</span><span class="n">Westfall</span> <span class="ow">and</span> <span class="n">Young</span><span class="p">)</span> <span class="n">correction</span>
<span class="p">[</span><span class="mf">0.000999</span>   <span class="mf">0.000999</span>   <span class="mf">0.41058941</span> <span class="mf">0.98001998</span> <span class="mf">0.99200799</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot distribution of third coefficient under null-hypothesis</span>
<span class="n">perms</span> <span class="o">=</span> <span class="n">coefs_perm</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span>

<span class="c1"># Re-weight to obtain distribution</span>
<span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">perms</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">/</span> <span class="n">perms</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">([</span><span class="n">perms</span><span class="p">[</span><span class="n">perms</span> <span class="o">&gt;=</span> <span class="n">perms</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">perms</span><span class="p">],</span> <span class="n">histtype</span><span class="o">=</span><span class="s1">&#39;stepfilled&#39;</span><span class="p">,</span>
         <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;beta&gt;beta obs (p-value)&quot;</span><span class="p">,</span> <span class="s2">&quot;beta&lt;beta obs&quot;</span><span class="p">],</span>
         <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="n">weights</span><span class="p">[</span><span class="n">perms</span> <span class="o">&gt;=</span> <span class="n">perms</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">weights</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Statistic distribution under null hypothesis&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">perms</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;observed statistic&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper left&quot;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../_images/resampling_50_0.png" src="../_images/resampling_50_0.png" />
<p>Given the logistic regression presented above and its validation given a
5 folds CV.</p>
<ol class="arabic simple">
<li><p>Compute the p-value associated with the prediction accuracy measured
with 5CV using a permutation test.</p></li>
<li><p>Compute the p-value associated with the prediction accuracy using a
parametric test.</p></li>
</ol>
</section>
<section id="bootstrapping">
<h2>Bootstrapping<a class="headerlink" href="#bootstrapping" title="Permalink to this headline">¶</a></h2>
<p>Bootstrapping is a statistical technique which consists in generating
sample (called bootstrap samples) from an initial dataset of size
<span class="math notranslate nohighlight">\(N\)</span> by randomly drawing with replacement <span class="math notranslate nohighlight">\(N\)</span> observations.
It provides sub-samples with the same distribution than the original
dataset. It aims to:</p>
<ol class="arabic simple">
<li><p>Assess the variability (standard error, <a class="reference external" href="https://sebastianraschka.com/blog/2016/model-evaluation-selection-part2.html#the-bootstrap-method-and-empirical-confidence-intervals">confidence
intervals.</a>)
of performances scores or estimated parameters (see Efron et
al. 1986).</p></li>
<li><p>Regularize model by fitting several models on bootstrap samples and
averaging their predictions (see Baging and random-forest).</p></li>
</ol>
<p>A great advantage of bootstrap is its simplicity. It is a
straightforward way to derive estimates of standard errors and
confidence intervals for complex estimators of complex parameters of the
distribution, such as percentile points, proportions, odds ratio, and
correlation coefficients.</p>
<ol class="arabic simple">
<li><p>Perform <span class="math notranslate nohighlight">\(B\)</span> sampling, with replacement, of the dataset.</p></li>
<li><p>For each sample <span class="math notranslate nohighlight">\(i\)</span> fit the model and compute the scores.</p></li>
<li><p>Assess standard errors and confidence intervals of scores using the
scores obtained on the <span class="math notranslate nohighlight">\(B\)</span> resampled dataset. Or, average
models predictions.</p></li>
</ol>
<p>References:</p>
<p><a class="reference external" href="https://projecteuclid.org/download/pdf_1/euclid.ss/1177013815">Efron B, Tibshirani R. Bootstrap methods for standard errors,
confidence intervals, and other measures of statistical accuracy. Stat
Sci
1986;1:54–75</a></p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>


<span class="c1"># Bootstrap loop</span>
<span class="n">nboot</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># !! Should be at least 1000</span>
<span class="n">scores_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;r2&quot;</span><span class="p">]</span>
<span class="n">scores_boot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">nboot</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">scores_names</span><span class="p">)))</span>
<span class="n">coefs_boot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">nboot</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>

<span class="n">orig_all</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="k">for</span> <span class="n">boot_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nboot</span><span class="p">):</span>
    <span class="n">boot_tr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">orig_all</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">orig_all</span><span class="p">),</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">boot_te</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">setdiff1d</span><span class="p">(</span><span class="n">orig_all</span><span class="p">,</span> <span class="n">boot_tr</span><span class="p">,</span> <span class="n">assume_unique</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">Xtr</span><span class="p">,</span> <span class="n">ytr</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">boot_tr</span><span class="p">,</span> <span class="p">:],</span> <span class="n">y</span><span class="p">[</span><span class="n">boot_tr</span><span class="p">]</span>
    <span class="n">Xte</span><span class="p">,</span> <span class="n">yte</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">boot_te</span><span class="p">,</span> <span class="p">:],</span> <span class="n">y</span><span class="p">[</span><span class="n">boot_te</span><span class="p">]</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtr</span><span class="p">,</span> <span class="n">ytr</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xte</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
    <span class="n">scores_boot</span><span class="p">[</span><span class="n">boot_i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">r2_score</span><span class="p">(</span><span class="n">yte</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">coefs_boot</span><span class="p">[</span><span class="n">boot_i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span>

<span class="c1"># Compute Mean, SE, CI</span>
<span class="n">scores_boot</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scores_boot</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">scores_names</span><span class="p">)</span>
<span class="n">scores_stat</span> <span class="o">=</span> <span class="n">scores_boot</span><span class="o">.</span><span class="n">describe</span><span class="p">(</span><span class="n">percentiles</span><span class="o">=</span><span class="p">[</span><span class="mf">.975</span><span class="p">,</span> <span class="mf">.5</span><span class="p">,</span> <span class="mf">.025</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;r-squared: Mean=</span><span class="si">%.2f</span><span class="s2">, SE=</span><span class="si">%.2f</span><span class="s2">, CI=(</span><span class="si">%.2f</span><span class="s2"> </span><span class="si">%.2f</span><span class="s2">)&quot;</span> <span class="o">%</span>\
      <span class="nb">tuple</span><span class="p">(</span><span class="n">scores_stat</span><span class="o">.</span><span class="n">loc</span><span class="p">[[</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;std&quot;</span><span class="p">,</span> <span class="s2">&quot;2.5%&quot;</span><span class="p">,</span> <span class="s2">&quot;97.5%&quot;</span><span class="p">],</span> <span class="s2">&quot;r2&quot;</span><span class="p">]))</span>

<span class="n">coefs_boot</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">coefs_boot</span><span class="p">)</span>
<span class="n">coefs_stat</span> <span class="o">=</span> <span class="n">coefs_boot</span><span class="o">.</span><span class="n">describe</span><span class="p">(</span><span class="n">percentiles</span><span class="o">=</span><span class="p">[</span><span class="mf">.975</span><span class="p">,</span> <span class="mf">.5</span><span class="p">,</span> <span class="mf">.025</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Coefficients distribution&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">coefs_stat</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">r</span><span class="o">-</span><span class="n">squared</span><span class="p">:</span> <span class="n">Mean</span><span class="o">=</span><span class="mf">0.59</span><span class="p">,</span> <span class="n">SE</span><span class="o">=</span><span class="mf">0.09</span><span class="p">,</span> <span class="n">CI</span><span class="o">=</span><span class="p">(</span><span class="mf">0.40</span> <span class="mf">0.73</span><span class="p">)</span>
<span class="n">Coefficients</span> <span class="n">distribution</span>
                <span class="mi">0</span>           <span class="mi">1</span>           <span class="mi">2</span>           <span class="mi">3</span>           <span class="mi">4</span>
<span class="n">count</span>  <span class="mf">100.000000</span>  <span class="mf">100.000000</span>  <span class="mf">100.000000</span>  <span class="mf">100.000000</span>  <span class="mf">100.000000</span>
<span class="n">mean</span>     <span class="mf">1.017598</span>    <span class="mf">1.053832</span>    <span class="mf">0.212464</span>   <span class="o">-</span><span class="mf">0.018828</span>   <span class="o">-</span><span class="mf">0.045851</span>
<span class="n">std</span>      <span class="mf">0.091508</span>    <span class="mf">0.105196</span>    <span class="mf">0.097532</span>    <span class="mf">0.097343</span>    <span class="mf">0.110555</span>
<span class="nb">min</span>      <span class="mf">0.631917</span>    <span class="mf">0.819190</span>   <span class="o">-</span><span class="mf">0.002689</span>   <span class="o">-</span><span class="mf">0.231580</span>   <span class="o">-</span><span class="mf">0.270810</span>
<span class="mf">2.5</span><span class="o">%</span>     <span class="mf">0.857418</span>    <span class="mf">0.883319</span>    <span class="mf">0.032672</span>   <span class="o">-</span><span class="mf">0.195018</span>   <span class="o">-</span><span class="mf">0.233241</span>
<span class="mi">50</span><span class="o">%</span>      <span class="mf">1.027161</span>    <span class="mf">1.038053</span>    <span class="mf">0.216531</span>   <span class="o">-</span><span class="mf">0.010023</span>   <span class="o">-</span><span class="mf">0.063331</span>
<span class="mf">97.5</span><span class="o">%</span>    <span class="mf">1.174707</span>    <span class="mf">1.289990</span>    <span class="mf">0.392701</span>    <span class="mf">0.150340</span>    <span class="mf">0.141587</span>
<span class="nb">max</span>      <span class="mf">1.204006</span>    <span class="mf">1.449672</span>    <span class="mf">0.432764</span>    <span class="mf">0.220711</span>    <span class="mf">0.290928</span>
</pre></div>
</div>
<p>Plot mean / CI</p>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">Statistics and Machine Learning in Python</a></h1>








<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../introduction/python_ecosystem.html">Python ecosystem for data-science</a></li>
<li class="toctree-l1"><a class="reference internal" href="../introduction/machine_learning.html">Introduction to Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../introduction/machine_learning.html#data-analysis-methodology">Data analysis methodology</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html">Import libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#basic-operations">Basic operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#data-types">Data types</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#execution-control-statements">Execution control statements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#list-comprehensions-iterators-etc">List comprehensions, iterators, etc.</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#functions">Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#regular-expression">Regular expression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#system-programming">System programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#scripts-and-argument-parsing">Scripts and argument parsing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#networking">Networking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#modules-and-packages">Modules and packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#object-oriented-programming-oop">Object Oriented Programming (OOP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#style-guide-for-python-programming">Style guide for Python programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#documenting">Documenting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#exercises">Exercises</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/scipy_numpy.html">Numpy: arrays and matrices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/scipy_pandas.html">Pandas: data manipulation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scientific_python/scipy_matplotlib.html">Data visualization: matplotlib &amp; seaborn</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../statistics/stat_univ.html">Univariate statistics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/stat_univ_lab_brain-volume.html">Lab: Brain volumes study</a></li>
<li class="toctree-l1"><a class="reference internal" href="../statistics/stat_multiv.html">Multivariate statistics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../statistics/time_series.html">Time series in python</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="decomposition.html">Linear dimension reduction and feature extraction</a></li>
<li class="toctree-l1"><a class="reference internal" href="manifold.html">Manifold learning: non-linear dimension reduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="clustering.html">Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="linear_regression.html">Linear models for regression problems</a></li>
<li class="toctree-l1"><a class="reference internal" href="linear_classification.html">Linear models for classification problems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/ml_supervized_nonlinear.html">Non-linear models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/ml_resampling.html">Resampling methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="ensemble_learning.html">Ensemble learning: bagging, boosting and stacking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimization/optim_gradient_descent.html">Gradient descent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/ml_lab_face_recognition.html">Lab: Faces recognition using various learning models</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../deep_learning/dl_backprop_numpy-pytorch-sklearn.html">Backpropagation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deep_learning/dl_mlp_mnist_pytorch.html">Multilayer Perceptron (MLP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deep_learning/dl_cnn_cifar10_pytorch.html">Convolutional neural network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deep_learning/dl_transfer-learning_cifar10-ants-bees_pytorch.html">Transfer Learning Tutorial</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, Edouard Duchesnay, NeuroSpin CEA Université Paris-Saclay, France.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.0.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/machine_learning/resampling.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>