
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Manifold learning: non-linear dimension reduction &#8212; Statistics and Machine Learning in Python 0.5 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="search" type="application/opensearchdescription+xml"
          title="Search within Statistics and Machine Learning in Python 0.5 documentation"
          href="../_static/opensearch.xml"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Clustering" href="clustering.html" />
    <link rel="prev" title="Linear dimension reduction and feature extraction" href="decomposition.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="manifold-learning-non-linear-dimension-reduction">
<h1>Manifold learning: non-linear dimension reduction<a class="headerlink" href="#manifold-learning-non-linear-dimension-reduction" title="Permalink to this headline">¶</a></h1>
<p>Sources:</p>
<ul class="simple">
<li><p><a class="reference external" href="http://scikit-learn.org/stable/modules/manifold.html">Scikit-learn
documentation</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Isomap">Wikipedia</a></p></li>
</ul>
<p>Nonlinear dimensionality reduction or <strong>manifold learning</strong> cover
unsupervised methods that attempt to identify low-dimensional manifolds
within the original <span class="math notranslate nohighlight">\(P\)</span>-dimensional space that represent high data
density. Then those methods provide a mapping from the high-dimensional
space to the low-dimensional embedding.</p>
<section id="multi-dimensional-scaling-mds">
<h2>Multi-dimensional Scaling (MDS)<a class="headerlink" href="#multi-dimensional-scaling-mds" title="Permalink to this headline">¶</a></h2>
<p>Resources:</p>
<ul class="simple">
<li><p><a class="reference external" href="http://www.stat.pitt.edu/sungkyu/course/2221Fall13/lec8_mds_combined.pdf">http://www.stat.pitt.edu/sungkyu/course/2221Fall13/lec8_mds_combined.pdf</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Multidimensional_scaling">https://en.wikipedia.org/wiki/Multidimensional_scaling</a></p></li>
<li><p>Hastie, Tibshirani and Friedman (2009). <em>The Elements of Statistical
Learning: Data Mining, Inference, and Prediction.</em> New York:
Springer, Second Edition.</p></li>
</ul>
<p>The purpose of MDS is to find a low-dimensional projection of the data
in which the pairwise distances between data points is preserved, as
closely as possible (in a least-squares sense).</p>
<ul class="simple">
<li><p>Let <span class="math notranslate nohighlight">\(\mathbf{D}\)</span> be the <span class="math notranslate nohighlight">\((N \times N)\)</span> pairwise distance
matrix where <span class="math notranslate nohighlight">\(d_{ij}\)</span> is <em>a distance</em> between points <span class="math notranslate nohighlight">\(i\)</span>
and <span class="math notranslate nohighlight">\(j\)</span>.</p></li>
<li><p>The MDS concept can be extended to a wide variety of data types
specified in terms of a similarity matrix.</p></li>
</ul>
<p>Given the dissimilarity (distance) matrix
<span class="math notranslate nohighlight">\(\mathbf{D}_{N \times N}=[d_{ij}]\)</span>, MDS attempts to find
<span class="math notranslate nohighlight">\(K\)</span>-dimensional projections of the <span class="math notranslate nohighlight">\(N\)</span> points
<span class="math notranslate nohighlight">\(\mathbf{x}_1, \ldots, \mathbf{x}_N \in \mathbb{R}^K\)</span>,
concatenated in an <span class="math notranslate nohighlight">\(\mathbf{X}_{N \times K}\)</span> matrix, so that
<span class="math notranslate nohighlight">\(d_{ij} \approx \|\mathbf{x}_i - \mathbf{x}_j\|\)</span> are as close as
possible. This can be obtained by the minimization of a loss function
called the <strong>stress function</strong></p>
<div class="math notranslate nohighlight">
\[\mathrm{stress}(\mathbf{X}) = \sum_{i \neq j}\left(d_{ij} -  \|\mathbf{x}_i - \mathbf{x}_j\|\right)^2.\]</div>
<p>This loss function is known as <em>least-squares</em> or <em>Kruskal-Shepard</em>
scaling.</p>
<p>A modification of <em>least-squares</em> scaling is the <em>Sammon mapping</em></p>
<div class="math notranslate nohighlight">
\[\mathrm{stress}_{\mathrm{Sammon}}(\mathbf{X}) = \sum_{i \neq j} \frac{(d_{ij} -  \|\mathbf{x}_i - \mathbf{x}_j\|)^2}{d_{ij}}.\]</div>
<p>The Sammon mapping performs better at preserving small distances
compared to the <em>least-squares</em> scaling.</p>
<section id="classical-multidimensional-scaling">
<h3>Classical multidimensional scaling<a class="headerlink" href="#classical-multidimensional-scaling" title="Permalink to this headline">¶</a></h3>
<p>Also known as <em>principal coordinates analysis</em>, PCoA.</p>
<ul class="simple">
<li><p>The distance matrix, <span class="math notranslate nohighlight">\(\mathbf{D}\)</span>, is transformed to a
<em>similarity matrix</em>, <span class="math notranslate nohighlight">\(\mathbf{B}\)</span>, often using centered inner
products.</p></li>
<li><p>The loss function becomes</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\mathrm{stress}_{\mathrm{classical}}(\mathbf{X}) = \sum_{i \neq j} \big(b_{ij} -  \langle\mathbf{x}_i, \mathbf{x}_j\rangle\big)^2.\]</div>
<ul class="simple">
<li><p>The stress function in classical MDS is sometimes called <em>strain</em>.</p></li>
<li><p>The solution for the classical MDS problems can be found from the
eigenvectors of the similarity matrix.</p></li>
<li><p>If the distances in <span class="math notranslate nohighlight">\(\mathbf{D}\)</span> are Euclidean and double
centered inner products are used, the results are equivalent to PCA.</p></li>
</ul>
</section>
<section id="example">
<h3>Example<a class="headerlink" href="#example" title="Permalink to this headline">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">eurodist</span></code> datset provides the road distances (in kilometers)
between 21 cities in Europe. Given this matrix of pairwise
(non-Euclidean) distances <span class="math notranslate nohighlight">\(\mathbf{D}=[d_{ij}]\)</span>, MDS can be used
to recover the coordinates of the cities in <em>some</em> Euclidean referential
whose orientation is arbitrary.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Pairwise distance between European cities</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;../datasets/eurodist.csv&#39;</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="k">except</span><span class="p">:</span>
    <span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://github.com/duchesnay/pystatsml/raw/master/datasets/eurodist.csv&#39;</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">5</span><span class="p">,</span> <span class="p">:</span><span class="mi">5</span><span class="p">])</span>

<span class="n">city</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;city&quot;</span><span class="p">]</span>
<span class="n">D</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:])</span>  <span class="c1"># Distance matrix</span>

<span class="c1"># Arbitrary choice of K=2 components</span>
<span class="kn">from</span> <span class="nn">sklearn.manifold</span> <span class="kn">import</span> <span class="n">MDS</span>
<span class="n">mds</span> <span class="o">=</span> <span class="n">MDS</span><span class="p">(</span><span class="n">dissimilarity</span><span class="o">=</span><span class="s1">&#39;precomputed&#39;</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">3000</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">mds</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">D</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>        <span class="n">city</span>  <span class="n">Athens</span>  <span class="n">Barcelona</span>  <span class="n">Brussels</span>  <span class="n">Calais</span>
<span class="mi">0</span>     <span class="n">Athens</span>       <span class="mi">0</span>       <span class="mi">3313</span>      <span class="mi">2963</span>    <span class="mi">3175</span>
<span class="mi">1</span>  <span class="n">Barcelona</span>    <span class="mi">3313</span>          <span class="mi">0</span>      <span class="mi">1318</span>    <span class="mi">1326</span>
<span class="mi">2</span>   <span class="n">Brussels</span>    <span class="mi">2963</span>       <span class="mi">1318</span>         <span class="mi">0</span>     <span class="mi">204</span>
<span class="mi">3</span>     <span class="n">Calais</span>    <span class="mi">3175</span>       <span class="mi">1326</span>       <span class="mi">204</span>       <span class="mi">0</span>
<span class="mi">4</span>  <span class="n">Cherbourg</span>    <span class="mi">3339</span>       <span class="mi">1294</span>       <span class="mi">583</span>     <span class="mi">460</span>
</pre></div>
</div>
<p>Recover coordinates of the cities in Euclidean referential whose
orientation is arbitrary:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="n">Deuclidean</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">pairwise</span><span class="o">.</span><span class="n">pairwise_distances</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">Deuclidean</span><span class="p">[:</span><span class="mi">5</span><span class="p">,</span> <span class="p">:</span><span class="mi">5</span><span class="p">]))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[[</span>   <span class="mf">0.</span> <span class="mf">3116.</span> <span class="mf">2994.</span> <span class="mf">3181.</span> <span class="mf">3428.</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">3116.</span>    <span class="mf">0.</span> <span class="mf">1317.</span> <span class="mf">1289.</span> <span class="mf">1128.</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">2994.</span> <span class="mf">1317.</span>    <span class="mf">0.</span>  <span class="mf">198.</span>  <span class="mf">538.</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">3181.</span> <span class="mf">1289.</span>  <span class="mf">198.</span>    <span class="mf">0.</span>  <span class="mf">358.</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">3428.</span> <span class="mf">1128.</span>  <span class="mf">538.</span>  <span class="mf">358.</span>    <span class="mf">0.</span><span class="p">]]</span>
</pre></div>
</div>
<p>Plot the results:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot: apply some rotation and flip</span>
<span class="n">theta</span> <span class="o">=</span> <span class="mi">80</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mf">180.</span>
<span class="n">rot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">theta</span><span class="p">),</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">theta</span><span class="p">)],</span>
                <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">theta</span><span class="p">),</span>  <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">theta</span><span class="p">)]])</span>
<span class="n">Xr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">rot</span><span class="p">)</span>
<span class="c1"># flip x</span>
<span class="n">Xr</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*=</span> <span class="o">-</span><span class="mi">1</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">Xr</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">Xr</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">city</span><span class="p">)):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">Xr</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">Xr</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">city</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="o">-</span><span class="mf">1894.0919178069155</span><span class="p">,</span>
 <span class="mf">2914.3554370871234</span><span class="p">,</span>
 <span class="o">-</span><span class="mf">1712.9733697197494</span><span class="p">,</span>
 <span class="mf">2145.437068788015</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../_images/manifold_5_1.png" src="../_images/manifold_5_1.png" />
</section>
<section id="determining-the-number-of-components">
<h3>Determining the number of components<a class="headerlink" href="#determining-the-number-of-components" title="Permalink to this headline">¶</a></h3>
<p>We must choose <span class="math notranslate nohighlight">\(K^* \in \{1, \ldots, K\}\)</span> the number of required
components. Plotting the values of the stress function, obtained using
<span class="math notranslate nohighlight">\(k \leq N-1\)</span> components. In general, start with
<span class="math notranslate nohighlight">\(1, \ldots K \leq 4\)</span>. Choose <span class="math notranslate nohighlight">\(K^*\)</span> where you can clearly
distinguish an <em>elbow</em> in the stress curve.</p>
<p>Thus, in the plot below, we choose to retain information accounted for
by the first <em>two</em> components, since this is where the <em>elbow</em> is in the
stress curve.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">k_range</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">D</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">stress</span> <span class="o">=</span> <span class="p">[</span><span class="n">MDS</span><span class="p">(</span><span class="n">dissimilarity</span><span class="o">=</span><span class="s1">&#39;precomputed&#39;</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="n">k</span><span class="p">,</span>
           <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">D</span><span class="p">)</span><span class="o">.</span><span class="n">stress_</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">k_range</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">stress</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">k_range</span><span class="p">,</span> <span class="n">stress</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;k&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;stress&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="mf">48644495.28571428</span><span class="p">,</span> <span class="mf">3356497.365752386</span><span class="p">,</span> <span class="mf">2858455.495887962</span><span class="p">,</span> <span class="mf">2756310.637628011</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Text</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s1">&#39;stress&#39;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../_images/manifold_7_2.png" src="../_images/manifold_7_2.png" />
</section>
<section id="exercises">
<h3>Exercises<a class="headerlink" href="#exercises" title="Permalink to this headline">¶</a></h3>
<p>Apply MDS from <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> on the <code class="docutils literal notranslate"><span class="pre">iris</span></code> dataset available at:</p>
<p><a class="reference external" href="https://github.com/duchesnay/pystatsml/raw/master/datasets/iris.csv">https://github.com/duchesnay/pystatsml/raw/master/datasets/iris.csv</a></p>
<ul class="simple">
<li><p>Center and scale the dataset.</p></li>
<li><p>Compute Euclidean pairwise distances matrix.</p></li>
<li><p>Select the number of components.</p></li>
<li><p>Show that classical MDS on Euclidean pairwise distances matrix is
equivalent to PCA.</p></li>
</ul>
<p>Manifold learning</p>
<p>Dataset S curve:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">mpl_toolkits.mplot3d</span> <span class="kn">import</span> <span class="n">Axes3D</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">manifold</span><span class="p">,</span> <span class="n">datasets</span>

<span class="n">X</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">make_s_curve</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="isomap">
<h2>Isomap<a class="headerlink" href="#isomap" title="Permalink to this headline">¶</a></h2>
<p>Isomap is a nonlinear dimensionality reduction method that combines a
procedure to compute the distance matrix with MDS. The distances
calculation is based on geodesic distances evaluated on neighborhood
graph:</p>
<ol class="arabic simple">
<li><p>Determine the neighbors of each point. All points in some fixed
radius or K nearest neighbors.</p></li>
<li><p>Construct a neighborhood graph. Each point is connected to other if
it is a K nearest neighbor. Edge length equal to Euclidean distance.</p></li>
<li><p>Compute shortest path between pairwise of points <span class="math notranslate nohighlight">\(d_{ij}\)</span> to
build the distance matrix <span class="math notranslate nohighlight">\(\mathbf{D}\)</span>.</p></li>
<li><p>Apply MDS on <span class="math notranslate nohighlight">\(\mathbf{D}\)</span>.</p></li>
</ol>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">isomap</span> <span class="o">=</span> <span class="n">manifold</span><span class="o">.</span><span class="n">Isomap</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">X_isomap</span> <span class="o">=</span> <span class="n">isomap</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="t-sne">
<h2>t-SNE<a class="headerlink" href="#t-sne" title="Permalink to this headline">¶</a></h2>
<p>Sources:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding">Wikipedia</a></p></li>
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/manifold.html#t-distributed-stochastic-neighbor-embedding-t-sne">scikit-learn</a></p></li>
</ul>
<p>Principles</p>
<ol class="arabic simple">
<li><p>Construct a (Gaussian) probability distribution between pairs of
object in input (high-dimensional) space.</p></li>
<li><p>Construct a (student) ) probability distribution between pairs of
object in embeded (low-dimensional) space.</p></li>
<li><p>Minimize the Kullback–Leibler divergence (KL divergence) between the
two distributions.</p></li>
</ol>
<p>Features</p>
<ul class="simple">
<li><p>Isomap, LLE and variants are best suited to unfold a single
continuous low dimensional manifold</p></li>
<li><p>t-SNE will focus on the <strong>local structure</strong> of the data and will tend
to extract clustered <strong>local groups</strong> of samples</p></li>
</ul>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tsne</span> <span class="o">=</span> <span class="n">manifold</span><span class="o">.</span><span class="n">TSNE</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;pca&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X_tsne</span> <span class="o">=</span> <span class="n">tsne</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Manifold Learning&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">131</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Spectral</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">view_init</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">72</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;2D &quot;S shape&quot; manifold in 3D&#39;</span><span class="p">)</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">132</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_isomap</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_isomap</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Spectral</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Isomap&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;First component&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Second component&quot;</span><span class="p">)</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">133</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_tsne</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_tsne</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Spectral</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;t-SNE&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;First component&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Second component&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="o">-</span><span class="mf">67.00072708129883</span><span class="p">,</span> <span class="mf">71.46007766723633</span><span class="p">,</span> <span class="o">-</span><span class="mf">20.22462863922119</span><span class="p">,</span> <span class="mf">15.324001502990722</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../_images/manifold_15_1.png" src="../_images/manifold_15_1.png" />
</section>
<section id="id1">
<h2>Exercises<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p>Run <a class="reference external" href="https://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html">Manifold learning on handwritten digits: Locally Linear Embedding,
Isomap with
scikit-learn</a></p>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">Statistics and Machine Learning in Python</a></h1>








<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../introduction/python_ecosystem.html">Python ecosystem for data-science</a></li>
<li class="toctree-l1"><a class="reference internal" href="../introduction/machine_learning.html">Introduction to Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../introduction/machine_learning.html#data-analysis-methodology">Data analysis methodology</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html">Import libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#basic-operations">Basic operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#data-types">Data types</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#execution-control-statements">Execution control statements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#list-comprehensions-iterators-etc">List comprehensions, iterators, etc.</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#functions">Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#regular-expression">Regular expression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#system-programming">System programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#scripts-and-argument-parsing">Scripts and argument parsing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#networking">Networking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#modules-and-packages">Modules and packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#object-oriented-programming-oop">Object Oriented Programming (OOP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#style-guide-for-python-programming">Style guide for Python programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#documenting">Documenting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/python_lang.html#exercises">Exercises</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/scipy_numpy.html">Numpy: arrays and matrices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/scipy_pandas.html">Pandas: data manipulation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scientific_python/scipy_matplotlib.html">Data visualization: matplotlib &amp; seaborn</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../statistics/stat_univ.html">Univariate statistics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/stat_univ_lab_brain-volume.html">Lab: Brain volumes study</a></li>
<li class="toctree-l1"><a class="reference internal" href="../statistics/stat_multiv.html">Multivariate statistics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../statistics/time_series.html">Time series in python</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="decomposition.html">Linear dimension reduction and feature extraction</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Manifold learning: non-linear dimension reduction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#multi-dimensional-scaling-mds">Multi-dimensional Scaling (MDS)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#isomap">Isomap</a></li>
<li class="toctree-l2"><a class="reference internal" href="#t-sne">t-SNE</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id1">Exercises</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="clustering.html">Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="linear_regression.html">Linear models for regression problems</a></li>
<li class="toctree-l1"><a class="reference internal" href="linear_classification.html">Linear models for classification problems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/ml_supervized_nonlinear.html">Non-linear models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/ml_resampling.html">Resampling methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="ensemble_learning.html">Ensemble learning: bagging, boosting and stacking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimization/optim_gradient_descent.html">Gradient descent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_gallery/ml_lab_face_recognition.html">Lab: Faces recognition using various learning models</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../deep_learning/dl_backprop_numpy-pytorch-sklearn.html">Backpropagation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deep_learning/dl_mlp_mnist_pytorch.html">Multilayer Perceptron (MLP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deep_learning/dl_cnn_cifar10_pytorch.html">Convolutional neural network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deep_learning/dl_transfer-learning_cifar10-ants-bees_pytorch.html">Transfer Learning Tutorial</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="decomposition.html" title="previous chapter">Linear dimension reduction and feature extraction</a></li>
      <li>Next: <a href="clustering.html" title="next chapter">Clustering</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, Edouard Duchesnay, NeuroSpin CEA Université Paris-Saclay, France.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.0.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/machine_learning/manifold.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>